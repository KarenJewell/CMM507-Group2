% $ biblatex auxiliary file $
% $ biblatex bbl format version 3.1 $
% Do not modify the above lines!
%
% This is an auxiliary file used by the 'biblatex' package.
% This file may safely be deleted. It will be recreated by
% biber as required.
%
\begingroup
\makeatletter
\@ifundefined{ver@biblatex.sty}
  {\@latex@error
     {Missing 'biblatex' package}
     {The bibliography requires the 'biblatex' package.}
      \aftergroup\endinput}
  {}
\endgroup


\refsection{0}
  \datalist[entry]{none/global//global/global}
    \entry{knitr2013}{manual}{}
      \name{author}{1}{}{%
        {{hash=25ce25b9d444076e0963bcf9fa3a6f92}{%
           family={Xie},
           familyi={X\bibinitperiod},
           given={Yihui},
           giveni={Y\bibinitperiod}}}%
      }
      \strng{namehash}{25ce25b9d444076e0963bcf9fa3a6f92}
      \strng{fullhash}{25ce25b9d444076e0963bcf9fa3a6f92}
      \strng{bibnamehash}{25ce25b9d444076e0963bcf9fa3a6f92}
      \strng{authorbibnamehash}{25ce25b9d444076e0963bcf9fa3a6f92}
      \strng{authornamehash}{25ce25b9d444076e0963bcf9fa3a6f92}
      \strng{authorfullhash}{25ce25b9d444076e0963bcf9fa3a6f92}
      \field{sortinit}{1}
      \field{sortinithash}{50c6687d7fc80f50136d75228e3c59ba}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{note}{R package version 1.4.1}
      \field{title}{knitr: A general-purpose package for dynamic report generation in R}
      \field{year}{2013}
      \verb{urlraw}
      \verb http://yihui.name/knitr/
      \endverb
      \verb{url}
      \verb http://yihui.name/knitr/
      \endverb
    \endentry
    \entry{ELYAN2017220}{article}{}
      \name{author}{2}{}{%
        {{hash=8ee870839373bdec087796433d91b98e}{%
           family={Elyan},
           familyi={E\bibinitperiod},
           given={Eyad},
           giveni={E\bibinitperiod}}}%
        {{hash=4ae93acfe7753c434ba98d1cca2121a9}{%
           family={Gaber},
           familyi={G\bibinitperiod},
           given={Mohamed\bibnamedelima Medhat},
           giveni={M\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
      }
      \strng{namehash}{983406f594dcc4cdc1cb866f56a9a08f}
      \strng{fullhash}{983406f594dcc4cdc1cb866f56a9a08f}
      \strng{bibnamehash}{983406f594dcc4cdc1cb866f56a9a08f}
      \strng{authorbibnamehash}{983406f594dcc4cdc1cb866f56a9a08f}
      \strng{authornamehash}{983406f594dcc4cdc1cb866f56a9a08f}
      \strng{authorfullhash}{983406f594dcc4cdc1cb866f56a9a08f}
      \field{extraname}{1}
      \field{sortinit}{2}
      \field{sortinithash}{ed39bb39cf854d5250e95b1c1f94f4ed}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{issn}{0020-0255}
      \field{journaltitle}{Information Sciences}
      \field{number}{Supplement C}
      \field{title}{A genetic algorithm approach to optimising random forests applied to class engineered data}
      \field{volume}{384}
      \field{year}{2017}
      \field{pages}{220\bibrangedash 234}
      \range{pages}{15}
      \verb{doi}
      \verb 10.1016/j.ins.2016.08.007
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1016/j.ins.2016.08.007
      \endverb
      \verb{url}
      \verb https://doi.org/10.1016/j.ins.2016.08.007
      \endverb
      \keyw{Random forests,Genetic algorithm,Class decomposition,Life science}
    \endentry
    \entry{Elyan2016}{article}{}
      \name{author}{2}{}{%
        {{hash=8ee870839373bdec087796433d91b98e}{%
           family={Elyan},
           familyi={E\bibinitperiod},
           given={Eyad},
           giveni={E\bibinitperiod}}}%
        {{hash=4ae93acfe7753c434ba98d1cca2121a9}{%
           family={Gaber},
           familyi={G\bibinitperiod},
           given={Mohamed\bibnamedelima Medhat},
           giveni={M\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
      }
      \strng{namehash}{983406f594dcc4cdc1cb866f56a9a08f}
      \strng{fullhash}{983406f594dcc4cdc1cb866f56a9a08f}
      \strng{bibnamehash}{983406f594dcc4cdc1cb866f56a9a08f}
      \strng{authorbibnamehash}{983406f594dcc4cdc1cb866f56a9a08f}
      \strng{authornamehash}{983406f594dcc4cdc1cb866f56a9a08f}
      \strng{authorfullhash}{983406f594dcc4cdc1cb866f56a9a08f}
      \field{extraname}{2}
      \field{sortinit}{3}
      \field{sortinithash}{a37a8ef248a93c322189792c34fc68c9}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Class decomposition describes the process of segmenting each class into a number of homogeneous subclasses. This can be naturally achieved through clustering. Utilising class decomposition can provide a number of benefits to supervised learning, especially ensembles. It can be a computationally efficient way to provide a linearly separable data set without the need for feature engineering required by techniques like support vector machines and deep learning. For ensembles, the decomposition is a natural way to increase diversity, a key factor for the success of ensemble classifiers. In this paper, we propose to adopt class decomposition to the state-of-the-art ensemble learning Random Forests. Medical data for patient diagnosis may greatly benefit from this technique, as the same disease can have a diverse of symptoms. We have experimentally validated our proposed method on a number of data sets that are mainly related to the medical domain. Results reported in this paper show clearly that our method has significantly improved the accuracy of Random Forests.}
      \field{issn}{1433-3058}
      \field{journaltitle}{Neural Computing and Applications}
      \field{month}{11}
      \field{number}{8}
      \field{title}{A fine-grained Random Forests using class decomposition: an application to medical diagnosis}
      \field{volume}{27}
      \field{year}{2016}
      \field{pages}{2279\bibrangedash 2288}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1007/s00521-015-2064-z
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1007/s00521-015-2064-z
      \endverb
      \verb{url}
      \verb https://doi.org/10.1007/s00521-015-2064-z
      \endverb
    \endentry
    \entry{8489087}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=8bdd958f269e992e266c71f8c678c5bc}{%
           family={Elyan},
           familyi={E\bibinitperiod},
           given={E.},
           giveni={E\bibinitperiod}}}%
        {{hash=99959bb17f4119ccde0c02a588aad019}{%
           family={Garcia},
           familyi={G\bibinitperiod},
           given={C.\bibnamedelimi M.},
           giveni={C\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{hash=6a2fd54a4a9478a4d73243581617574f}{%
           family={Jayne},
           familyi={J\bibinitperiod},
           given={C.},
           giveni={C\bibinitperiod}}}%
      }
      \strng{namehash}{007bee4fe6bcdc400f110a129495dc42}
      \strng{fullhash}{007bee4fe6bcdc400f110a129495dc42}
      \strng{bibnamehash}{007bee4fe6bcdc400f110a129495dc42}
      \strng{authorbibnamehash}{007bee4fe6bcdc400f110a129495dc42}
      \strng{authornamehash}{007bee4fe6bcdc400f110a129495dc42}
      \strng{authorfullhash}{007bee4fe6bcdc400f110a129495dc42}
      \field{sortinit}{4}
      \field{sortinithash}{e071e0bcb44634fab398d68ad04e69f4}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{2018 International Joint Conference on Neural Networks (IJCNN)}
      \field{issn}{2161-4407}
      \field{month}{7}
      \field{title}{Symbols Classification in Engineering Drawings}
      \field{year}{2018}
      \field{pages}{1\bibrangedash 8}
      \range{pages}{8}
      \verb{doi}
      \verb 10.1109/IJCNN.2018.8489087
      \endverb
      \keyw{engineering;pattern classification;symbol manipulation;technical drawing;unsupervised learning;symbols classification;technical drawings;labeled dataset;machine learning algorithms;unsupervised learning algorithms;engineering drawings;Process and Instrumentation;Engineering drawings;Standards;Industries;Machine learning algorithms;Task analysis;Complexity theory;Oils}
    \endentry
  \enddatalist
\endrefsection
\endinput

