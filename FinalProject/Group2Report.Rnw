\documentclass[10pt]{article}
\usepackage{graphicx, verbatim}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amscd}
\usepackage{lipsum}
\usepackage{blindtext}
\usepackage{todonotes}
\usepackage[tableposition=top]{caption}
\usepackage{ifthen}
\usepackage{caption}
\setlength{\textwidth}{6.5in} 
\setlength{\textheight}{9in}
\setlength{\oddsidemargin}{0in} 
\setlength{\evensidemargin}{0in}
\setlength{\topmargin}{-1.5cm}
\setlength{\parindent}{0cm}
\usepackage{setspace}
\usepackage{float}
\usepackage{fancyhdr}
\usepackage{tabularx}
\usepackage{soul} 

\usepackage{hyperref}
\hypersetup{
  colorlinks   = true, %Colours links instead of ugly boxes
  urlcolor     = blue, %Colour for external hyperlinks
  linkcolor    = blue, %Colour of internal links
  citecolor   = red %Colour of citations
}

\usepackage[backend=biber ,sorting=none]{biblatex}
\bibliography{references}
\begin{filecontents*}{references.bib}
\end{filecontents*}


%\fancyhf{}
\rfoot{Group 2 \thepage}
\singlespacing
\usepackage[affil-it]{authblk} 
\usepackage{etoolbox}
\usepackage{lmodern}

% \makeatletter
% \renewcommand{\maketitle}{\bgroup\setlength{\parindent}{16pt}
% \begin{flushleft}
%   \textbf{\@title}
% 
%   \@author
% \end{flushleft}\egroup
% }

%\renewcommand\Authfont{\fontsize{14}{18.4}\selectfont}
%\makeatother

% \pagestyle{fancy}
% \rfoot{Page \thepage}
 %\thispagestyle{empty} 

<<include=FALSE>>=
# Setting global chunk options
opts_chunk$set(
  eval = TRUE, 
  echo = FALSE, 
  message = FALSE, 
  warning = FALSE, 
  results='markup', 
  fig.width=6, 
  fig.height=2.5, 
  size="small", 
  out.width = "1\\linewidth", 
  tidy.opts=list(width.cutoff=60), 
  tidy=TRUE)
@


\begin{document}


\title{\LARGE Plastic Pollution in Oceans  \\ Group 2 Report - CMM507}

\author{ALEXANDER RITCHIE, \textit{\href{1911218@rgu.ac.uk}{1911218@rgu.ac.uk}};\\ GEORGIOS ORFANAKIS, \textit{\href{1903446@rgu.ac.uk}{1903446@rgu.ac.uk}};\\ KAREN JEWELL, \textit{\href{1415410@rgu.ac.uk}{1415410@rgu.ac.uk}};\\ ROSHI SHRESTHA, \textit{\href{1903445@rgu.ac.uk}{1903445@rgu.ac.uk}};\\ STUART WATT, \textit{\href{1501869@rgu.ac.uk}{1501869@rgu.ac.uk}}}

\maketitle
% \begin{flushleft} \today \end{flushleft} 
\noindent\rule{16cm}{0.4pt}
%\underline{\hspace{3cm}
\ \\
%\thispagestyle{empty}

\section{Introduction}



\subsection{Problem Statement}\label{statement}

Plastic pollution is a serious problem in the marine environment where they have major impact on marine and human health. In order to understand the depth of the problem, it is essential to understand the amount and composition of marine litter. This can help in applying various mitigation strategies. This section will include:
\begin{itemize}
\item An overview of the marine pollution
\item Motivation behind this topic
\item Aim and objectives of this report
\end{itemize}


\subsection{Overview}\label{over}

Marine pollution is a major global issue which impacts on environment, economy and human health. Although marine pollution is caused by many different materials, plastics consist of 60-80\% of the marine litter. Synthetic organic polymer derived from polymerisation of monomers extracted from oil and gas make up the plastics.\cite{DERRAIK2002} \cite{RIOS2007} The lightweight feature and its durability make it very suitable to make a range of products that we use in our everyday life.\cite{BARNES2009} \cite{SIVAN2011} These same features have been a major cause of pollution due to overuse and non-managed waste disposal system worldwide with plastic contributing to the 10\% of the waste generated worldwide.\cite{BARNES2009} Due to its buoyancy, plastic debris can be dispersed over long distances and they can persist for a long time. Although, plastic litter has been a major cause of marine pollution for a while, its seriousness has only been realised recently. Jambeck et al.,\cite{JAMBECK2015} reported that in 2010 alone, between 4.8 million to 12.7 million metric tons of plastics entered the ocean. Plastics are now everywhere in the marine environment and urgent action is required to mitigate this problem and reduce the harmful impact.\cite{RIOS2007} \cite{ROCHMAN2015}



\subsection{Motivation}\label{mot}

Impact of plastic pollution on marine life have been reviewed extensively. \cite{GALL2015} \cite{KUHN2015} \cite{RYAN2015} \cite{WILLIAMS2019} Over 700 marine wildlife species are affected due to entanglement in plastic ropes and materials and in- gestion of plastics in the ocean.\cite{GALL2015} Over 340 species of marine animals were found to be entangled. \cite{KUHN2015} Over time plastic disintegrates into small microplastics which are easily consumed by fish from where they enter the food chain. Plastics have been found in a third of fish caught in the UK which included the popular fishes such as cod, haddock and mackerel (Lusher et al., 2013). Impact of plastic entering the human food chain and the effects are still to be studied. Plastic toxicity and the occurrence of microplastics and nanoplastics in the water supply can also be a direct impact on human health in addition to the contamination in seafood.\cite{ROCHMAN2015} \cite{MARKIC2020} \\

Reducing plastic pollution has recently been a global aim. Research in plastic pollution in marine environment has played a big role in reducing it and raising awareness all over the world. In order to understand the plastic pollution in marine environments and its effect in long term, it is essential to keep collecting data on patterns of marine debris around the world. Effective monitoring of plastic debris is very essential in order to reduce the abundance of plastic debris everywhere. In addition, monitoring the type, frequency and the source of the litter is also important for prevention initiative of marine pollution. Most of the monitoring are done by surveys looking at frequencies of beach litter collected by organisations and volunteers.\cite{COE1997} Most abundant litter can be found close to urban areas where beach visitor numbers are higher.\cite{GARRITY1993}


\subsection{Objectives }\label{obj}

The main objectives of this project are outlined as follows:
\begin{itemize}	
\item To research marine plastic problems and their impacts
\item To find a dataset suitable for this study
\item	Look at the composition of litter collected 
\item	Summarise the results that were found
\end{itemize}


\pagebreak
\section{Research}\label{research}

Things we found

Sources of pollution: 10 river dataset, 50km2 coastline dataset, pollution density and body of water dataset....

Georgios' review below\\

Our group conducted some literature research in order to identify how researchers have been trying to monitor the problem of coast pollution, what are some basic findings they have had and problems they have encountered in the process.\\

Several studies have reported the abundance of plastic as a coastal litter through survey and citizen science. A 12-year dataset on coastal debris pollution in Taiwan using Citizen science also revealed that most debris items found were plastic. \cite{WALTHER2018} 19 categories of debris items were collected during the clean-up events. The five most commonly recorded debris categories were plastic shopping bags, plastic bottle caps, disposable tablewares, fishing equipment, and plastic drinking straws. \\

There have been many other studies around the world regarding littering of the shores. A study in Western Japan and eastern coasts of Russia found out that 55\% to 93.4\% of items over the Japanese shores were plastic. The second most abundant item was resin pellet, which is a form of plastic too. For the eastern Russian coast plastic items were also the most abundant ~55\% litter, with plastic fragments being the most abundant within the plastics category. The composition of litter was similar in the two countries, although the concentration of plastics was much higher in Japan. \cite{KUSUI2003} \\

Further on the Asian upper east, hard plastic and Styrofoam were the dominant plastic types on Korean beaches. On average, hard plastic and Styrofoam comprised 32\% and 48.5\% (by number) of the total debris, respectively. \\
An important aspect put in this survey is the part of the beach from which litter is being collected. As mentioned in the research, most studies work on data from the high strandline so they do not produce representative pollution data for the whole beach environment.  So, considering that the high strandline accounts for a very small proportion of the whole beach area, micro- and mesoplastic abundance expressed in terms of items per area (items/m2) or volume (items/m3) may produce highly biased information on beach plastic pollution.\\
Another important aspect is that hard plastic found in high proportion on certain location may have to do with these locations being highly urbanized and populated, whereas for high Styrofoam accumulation locations it was found that these were places with dense aquaculture fields.
\cite{LEE2017} \\

In an older study over the region of Caribbean the most common types of debris stranded on the Caribbean coast of Panama were plastic and Styrofoam, with plastics being household or consumer related. Styrofoam packing materials were also abundant, and may have come from trans-shipment activities of Colon's Free Zone, as well as from household trash or from offshore. \cite{ GARRITY1993} \\

Interestingly, in a study carried out on the beach of Ensenada, Baja California, Mexico reported wood as the most abundant litter. \cite{SILVA2003} However, this study only looked at one season and more data would be required to confirm this result. \\

A recent annual study (2016/2017) on 8 beaches in Tenerife in Canary island also found that plastic was the most abundant litter. They also reported that there were more accumulated plastic debris in remote beaches compared to the beaches near the city indicating that more debris were transported by tides. More long term study is required to look at the changes in the results reported over time. \cite{REINOLD2020} \\

As one may easily observe there are quite a few variations in terms of how studies over litter accumulation are conducted. The variation has to do with the time span of the research, the part of the beach from which litter is collected, as well as the categorization of littering. This creates a problem when researchers want to investigate a problem and compare different studies. \\
The problem basically amounts to assessing changes in accumulation rates and composition, trends over time and the effectiveness of management systems, a hard task without good monitoring methodologies. Although monitoring of marine litter is currently carried out within a number of countries around the world, the methods of survey and monitoring used tend to be very different, preventing comparisons and harmonization of data across regions or time-scales.\\

This is why the scientific community has been trying to create some common ground which has led to some initiatives joined by many countries worldwide. One of them and probably the most important one is the International Clean Coast (ICC) program-a new, long-term approach for cleaner beaches by various activities such as an increase in the public awareness. \cite{ CHESHIRE2009} This initiative aimed at a comprehensive litter characterization scheme to be developed that uses both material composition and form. This allows Litter Monitoring Repeated surveys of beaches, sea bed and/or surface waters to determine litter quantities such that information can be compared with baseline data to see if changes occur through time and / or in response to management arrangements.

The ICC uses some specific developed categorizations of coast litter, with the most accepted one being the Clean Coastal Index (CCI) protocol, which is very useful, in terms of simplicity and information provided, allowing comparison between different times and places. The CCI protocol is very different from most others having a focus on operational clean-up of beaches as. The CCI is suggested as a tool for evaluation of the actual coast cleanliness. It measures plastic debris as a beach cleanliness indicator, in an easy way precluding bias by the assessor. The CCI also proved to be a useful tool for measuring progress and the success of activities such as education campaigns, media coverage and enforcement actions. \cite{ALKALAY2007} \\

A study in Israel followed the CCI protocol and found out that plastic is the most ubiquitous beach litter item.  An important contribution of this study has to do with comparing its findings with other Mediterranean beaches showing that plastic might be the dominant pollutant, though non-plastic litter is highly specific to the region and cannot be treated universally. \cite{PORTMAN2017}

In a study on litter pollution in a region of India, once again the CCI protocol for the categorization of litter was followed. Once again plastic was the main source of litter ~45\%, with plastic bags topping the index at ~33\%, followed by food wrappers and then plastic cups. Cigarettes/cigar tips were scarcely found amounting to only 5.5\%. \cite{KUMAR2016} \\

The use of the common protocol in these two studies allows for researchers to compare their findings and create common plastic pollution models, even though the two coasts are continents apart. \\

Another study conducted at the other side of the Mediterranean, in Cadiz, found that plastic bottles/containers were the most frequent items followed by plastic bags. This research points out that surveys are heavily affected by clean-ups performed at beaches which the importance this activity offers in the shore staying clean.  \cite{WILLIAMS2016} So even though this study reaches to some important conclusions even on ways to clean coasts the right way, it cannot be easily compared, or its conclusions easily applied even with the case of the study in Israel, which is also in the Mediterranean.\\

Given the literature above, our group went on to work with a world-wide coastal littering dataset spanning a timeframe of a decade with an interest to see if its findings match the above: be it if plastic is the most abundant litter, within the plastic categories which are the most important subclasses found and could there be a way to computationally monitor the coastal littering problem. For this we followed the CCI categorization of litter.



\pagebreak
\section {Methods}\label{methods}

This paper is conducted using secondary data collection methods only. The authors did not collect or create any new data using primary methods.


\subsection{Dataset Description}\label{dataset}
%\Where the dataset came from; How it is constructed: multiple csv files by year; A description of what it is, what's in it and what it represents; Problems with the dataset: Missing data; data anomalies (lat/long values don't match named regions)

\hl{Can we also add to this information of how the data is entered e.g. optional/mandatory fields, free-text or dropdown fields. The use of IDs suggest these are option fields with lookup tables somewhere.}

\begin{itemize}

\item The data was taken from  \textit{\href{http://marinedebris.engr.uga.edu/newmap/}{marine debris tracker}} between 2010 till February 19th 2020. The time of 2010 was chosen as there was no data before that time.
\item The dataset was composed by combining the multiple csv files gathered from the marine debris tracker into a single set after this was done the date data type was renamed "Time". 
\item The dataset created from the combined csv files contain more than 360000 rows of data and consists of the folowing variables. 
\end{itemize}


\begin{table}[H]
\begin{tabular}{ l l l }
Variable & Description & Mandatory \\
\hline
ListID  & the ID code for the list & non mandatory \\
ListName & the name of the list & non mandatory \\
ItemID & ID code given to the item of debris & non mandatory \\
ItemName & name we give to item of debris & mandatory \\
LogID &  ID code given to the location of the debris & non mandatory \\
Quantity & number of pieces of debris in the observation & mandatory? \\
Error radius & radius around the observation site within the error for reasonable doubt & mandatory \\
Latitude & coordinates of the location where the observation was made & mandatory \\
Longitude & coordinates of the location where the observation was made & mandatory \\
Altitude & coordinates of the location where the observation was made & mandatory \\
Location & area the observation of debris was made in & non mandatory \\
Description & description of the area the debris was found in & non mandatory \\
MaterialID & ID code of the material that the debris was composed of & non mandatory \\
MaterialDescription & description of material the debris was composed of & mandatory\\ 
Time & time of observation & non mandatory \\
\end{tabular}
\end{table}

\subsection{Dataset Pre-processing}
%\Because of the features and concerns identified in the section above, we chose to transform the dataset in the following ways:reclassified some labels because variation was too high (there were too many labels); removed missing values; removed certain subsets; but kept certain subsets


<<include = FALSE>>=
library(tidyverse)
library(purrr)
library(magrittr)
library(treemap)
library(mapdata)
library(viridis)
library(lubridate)
library(imager)
library(xtable)
library(dplyr)


data <- list.files(path = "data/debris/", full.names = TRUE) %>% 
  lapply(FUN = read_csv, col_types = "ififidddddcfcif") %>% 
  reduce(rbind)
@


<<>>=
# Data wrangling

#replace the column for time as a date data type, renaming it "Time" 
data$Time <- data$Timestamp %>% 
  parse_datetime(format = "%Y%m%d%H%M%S")
data$Timestamp <- NULL

#MissingValues
data %>% select_if(function(x) any(is.na(x))) %>% colnames()
#explicit missing value for the location factor
data$Location <- data$Location %>% fct_explicit_na()

#Remove redundant data
data <- data %>% select(-ListID,-ListName)
@
The following actions were performed on the dataset:

'ListID', 'ListName', 'ItemID' \hl {(couldn't delete 'itemid' because it's being used in a chart below)} and 'Material ID' were found to be redundant and removed from the dataset as they all have accompanying textual descriptions which are more meaningul.
\\
Nulls found in ItemName and Description.\\ 
\hl{this means every entry has a material at least? why? could be a required field? that would explain why some entries are rubbish if people are forced to pick a category}
\hl{it is also worth discussing the merits of dropdown entries: standardises input but forces a value where none might be appropriate, or a default it selected?}
\\
\hl{Stuart: Yes, it is a required field. I checked on the mobile app and you select a item type from different material sections. Note however that there is a material type \emph{Other Items} which contains the items \emph{Other} and \emph{Test Item}. Therefore users are able to categorise an item as other if it is not appropriate for any other option on the list.}
\\
\hl{also maybe worth looking at: what's the significance of some of these itemIDs where the itemname is blank? It could be an item once that was then deleted or categorised retrospectively. Do a groupby ItemID and see if more than one material or item name turns up.}\\
\\
Unique values for each column: \hl{can we present these unique counts as a formatted table? I think it's interesting that 55 unique items can have \~8k descriptions}
<<>>=
data %>% apply(2, function(x) length(unique(x)))


@

\subsection{Data Quality Issues: Classification}
The authors find that there are multiple instances of missclassified items. Where their descriptions appear to not match their material categorisation\\
Lets see if there are any "ItemNames" associated with more than one "Material Descriptions".
<<>>=
data %>% select(`Material Description`, ItemName) %>%
  distinct() %$% 
  table(ItemName) %>% 
  as_tibble() %>% 
  filter(n > 1)
@
So rubber gloves are associated with two material descriptions, but otherwise a one to many relationship exists between "Material Description" and "ItemName".
<<>>=
data %>% select(`Material Description`, ItemName, Quantity) %>%
  filter(ItemName == "Rubber Gloves") %>% 
  group_by(`Material Description`) %>% 
  summarise(Quantity = sum(Quantity))
@
It seems that most rubber gloves are classified as plastic rather than rubber.
<<>>=
data %>% select(`Material Description`, ItemName, Description) %>%
  filter(ItemName == "Rubber Gloves", !is.na(Description))
@
All instances of rubber gloves with non-missing descriptions are categorised as plastic. We also see that the descriptions suggest that the categorisation may be innaccurate: the last two instances here have "Balloon" in the extra descriptions... why aren't they categorised as such?
\hl{another thing maybe worth looking at: all MATERIALS!=Plastic yet have the term "plastic" in the description. could further expand this to descriptions which have any of the material terms in them, but is not its own material. further explores the point about missclassified data.}





\subsection{Recategorisation}


After the issues with the dataset that were identified in the section above, it was decided that it would be best to transform the dataset in the following ways:
\begin{itemize}
\item reclassified some labels because variation was too high (there were too many labels)
\item The values of the missing data were removed.
\item It was decided that subsets that were not needed were removed while retaining the necessary subsets.
\end{itemize}

\begin{figure}[H] %start a figure
\begin{center}
<<>>=
plastic_ordered <- data %>% 
  filter(`Material Description` == "PLASTIC") %>% 
  select(ItemName, Quantity) %>% 
  group_by(ItemName) %>% 
  summarise(Total = sum(Quantity)) %>% 
  arrange(desc(Total))

data %>% 
  filter(`Material Description` == "PLASTIC") %>% 
  mutate(month = month(Time, label = TRUE), 
         year = as.integer(year(Time)),
         ItemName = fct_infreq(ItemName)) %>% 
  filter(year > 2010) %>% 
  group_by(month, year, ItemName) %>%
  summarise(`Total Quantity` = sum(Quantity)) %>% 
  ggplot(aes(x = month, y = `Total Quantity`, fill = ItemName)) +
    geom_col(colour = "black", size = 0.2, position = "fill") +
    facet_wrap(~year, nrow = 4) +
    scale_fill_hue(l=50, c=150) +
    xlab("Month") +
    ylab("Proportion of Items") +
    theme(legend.position="bottom",
          legend.text=element_text(size=4)) # --- Change legend text size here! ---
    #scale_fill_viridis_d(option = "magma")

#ggsave("plots/pastic_debris_plot.png", width = 40, height = 20, units = "cm")
@
\caption {Debris by categorisation}
\label{figE}
\end {center}
\end {figure}




\hl{Adjust legend text size in annotated code below. - Stuart}
\begin{figure}[H] %start a figure
\begin{center}
<<>>=  
# all cigarette related waste: 1, 4, 6, 22
# Food related waste: 3, 2,7,9,10, 17, 23, 11
# Non food related waste: 8, 14, 15, 16, 18, 19, 21, 20
# Plastic bags and Styrofoam packaging:12, 13
# Fragments: 5, 23, 24,25

recategorise <- function(x){
  out = ""
  if(x %in% c(1,4,6,22)){out = "Cigarette related waste"}
  if(x %in% c(2,3,7,9,10,17,23,11)) out = "Food related waste"
  if(x %in% c(8,14,15,16,18,19,21,20)) out = "Other"
  if(x %in% c(12,13)) out = "Plastic bags and Styrofoam packaging"
  if(x %in% c(5,23,24,25)) out = "Fragments"
  if(out == "") stop(paste("Error in recategorise:", x))
  return(out)
}

plastic_types <- data %>% 
  filter(`Material Description` == "PLASTIC") %>% 
  select(ItemName, ItemID) %>% 
  distinct() %>% 
  mutate(label = 1:n()) %>% 
  mutate(category = purrr::map(label, recategorise)) %>%
  mutate(category = as_factor(as.character(category))) %>% 
  select(ItemID, category)


plastic <- data %>% 
  filter(`Material Description` == "PLASTIC") %>% 
  full_join(plastic_types, by = "ItemID")

ordered_levels <- plastic %>%
  group_by(category) %>% 
  summarise(totObs = sum(Quantity)) %>% 
  ungroup() %>% 
  arrange(desc(totObs)) %>% 
  select(category) %$%
  category
plastic$category <- factor(plastic$category, levels = ordered_levels)
rm(ordered_levels)


plastic %>% 
  mutate(month = month(Time, label = FALSE), 
         year = as.integer(year(Time))) %>% 
  filter(year > 2010) %>% 
  group_by(month, year, category) %>%
  summarise(`Total Quantity` = sum(Quantity)) %>% 
  ggplot(aes(x = month, y = `Total Quantity`, fill = category)) +
    geom_col(colour = "black", size = 0.2, position = "fill") +
    facet_wrap(~year, nrow = 2) +
    scale_fill_viridis(discrete = TRUE, option = "plasma") +
    xlab("Month") +
    ylab("Proportion of Items") +
    ggtitle("Rel. frequencies of observed plastic waste by category") +
    scale_x_continuous(breaks = 1:12) +
    theme(panel.grid.major.x = element_blank(),
          panel.grid.minor.x = element_blank(),
          legend.position = "bottom",
          legend.text=element_text(size=5)) + # --- Change legend text size here! ---
    guides(fill=guide_legend(title="Category"))

#ggsave("plots/pastic_debris_plot_recategorised.png", width = 40, height = 20, units = "cm")

@
\caption {Recategorisation by year. Colour scale ordered by ranking of total observed quantity.}
\label{figB}
\end {center}
\end {figure}



\pagebreak
\section{Exploration}

Here we describe the things we found... 

\subsection{Proportion Trends}
How pollutant proportions change over time.\\
\\
Cigarette butts proportions and raw counts decrease over time: possibly less people smoking, or moving to vaping\\
\\
General pollution count going down over time?\\
\\
Old pollutants fall away (cigarette butts) but new ones are introduced\\
\\
Question: Are observed plastic item proportions time invariant?\\
\\

\begin{figure}[H] %start a figure
\begin{center}
<<>>=
#Linechart quantity of debris per year
data %>% 
  mutate(year = year(Time)) %>% 
  filter(year > 2010, year < 2020) %>% 
  group_by(year) %>% 
  summarise(quan = sum(Quantity)) %>% 
  ggplot(aes(x = year, y = quan)) +
    geom_col() +
    scale_x_continuous(breaks = 2011:2019) +
    xlab("Year") +
    ylab("Quantity") +
    ggtitle("Quantity of debris per year") +
    theme(panel.grid.major.x = element_blank(),
          panel.grid.minor.x = element_blank()) +
    scale_y_continuous(labels = scales::label_number_si(accuracy = 1))

#ggsave("plots/observations.png")
@
\caption {Trend of debris observered}
\label{figD}
\end {center}
\end {figure}


\begin{figure}[H] %start a figure
\begin{center}
<<>>=
#Histogram of observations: Total v Plastic
data %>% 
  mutate(Type = if_else(`Material Description` == "PLASTIC", "Plastic", "Other"),
         months = floor_date(Time, 'month')) %>% 
  group_by(months, Type) %>% 
  summarize(`Number of observations` = n()) %>% 
  ggplot(aes(x = months, y = `Number of observations`)) +
    geom_area(aes(fill = Type)) +
    theme(legend.position = "bottom")
  # ggplot() +
  # geom_histogram(aes(x = Time))
  
@
\caption {Observations of plastic debris v all debris}
\label{figF}
\end {center}
\end {figure}


\subsection {Distribution of observed debris:}

MaterialQuantities\\

\begin{figure}[H] %start a figure
\begin{center}
<<>>=
data %>% select(Quantity,Description,`Material Description`) %>% 
  group_by(`Material Description`) %>% 
  summarise(Quantity = sum(Quantity)) %>% 

  ggplot(aes(x = reorder(`Material Description`, Quantity), y = Quantity)) +
    geom_col() +
    ylab("Total recorded quantity") +
    xlab("Material class") +
    coord_flip()
@
\caption {Material Quantities}
\label{figC}
\end {center}
\end {figure}

So the most populated material class is Plastic. Note that this does not necessarily mean that plastic is the largest quantity of debris, just that the individual number of items categorised is largest.

A tree map of material quantities:
\begin{figure}[H] %start a figure
\begin{center}
<<fig=TRUE>>=
#treemap of debris categories
#png("plots/treemap.png")
data %>% 
  select(`Material Description`, ItemName, Quantity) %>% 
  group_by(`Material Description`, ItemName) %>% 
  summarise(Quantity = sum(Quantity)) %>% 
  treemap(index = c("Material Description", "ItemName"),
          vSize = "Quantity", draw = TRUE) -> tm
#tm
#dev.off()
#save.image(file = "plots/treemap.png")
@
\caption {Debris categorisation}
\label{figI}
\end {center}
\end {figure}

Cigarettes are the most common item recorded as seen in. %Figure~\ref{figI}
Perhaps some of the debris is not actually from the sea, but rather from people littering by the coastline? Does debris littered on the coastline end up in the oceans?

\hl{This is a great chart, but not the best to support the statement that cigarettes is most popular - a column or bar chart here will be much better (area charts are not as effective as charts you can level-compare), potentially use proportions or data labels to further drive the point that it IS the largest. Treemap suggest moving back into pre-processing section.}


\begin{figure}[H] %start a figure
\begin{center}
<<fig=TRUE, fig.height=4>>=
#bar of debris categories
data %>% 
  select(`Material Description`, ItemName, Quantity) %>% 
  group_by(`Material Description`, ItemName) %>% 
  summarise(Quantity = sum(Quantity)) %>% 
  ggplot(aes(x=reorder(`ItemName`, -Quantity), y=Quantity, fill=`Material Description`)) +
  geom_bar(stat="identity") +
  ggtitle("Debris Categorisation") +
  xlab("Debris") + 
  ylab("") +
  #coord_flip() +
  theme(text = element_text(size=8),
        axis.text.x=element_text(angle=90, hjust=1),
        plot.title = element_text(size=10),
        legend.text=element_text(size=5),
        legend.position = "bottom")
  #treemap(index = c("Material Description", "ItemName"),
  #        vSize = "Quantity", draw = TRUE) -> tm

@
\caption {Debris categorisation}
\label{figI2}
\end {center}
\end {figure}

\hl{maybe make this top 10 or 15 items.}


\subsection{Event-Driven Pollution}

Fireworks found in July and North-America only: possibly 4th July celebrations\\
4th July and Firework link? (Karen's Idea)\\

\begin{figure}[H] %start a figure
\begin{center}
<<fig=TRUE>>=
#Boxplot of fireworks distribution by month (across all years)
data %>% 
  filter(`Material Description` == "PLASTIC",
         ItemName %in% c("Fireworks"),
         year(Time) >= 2012, year(Time) <= 2019) %>% 
  mutate(month = month(Time, label = TRUE), 
         year = as.integer(year(Time))) %>% 
  group_by(month, year) %>% 
  summarise(quantity = sum(Quantity)) %>% 
  ggplot() +
    geom_boxplot(aes(x = month, y = quantity)) +
    xlab("Month") +
    ylab("Quantity") +
    ggtitle("Firework debris 2012-2019")

#ggsave("plots/fireworks.png")
@

\caption {Boxplot of fireworks distribution by month, across all years}
\label{figA}
\end {center}
\end {figure}





\subsection{Location-Driven Pollution}

Rubber found in Indoneasia only: possibly a recording bias.\\

Certain classes are found in certain regions only: not because they don't exist elsewhere but because of recording bias focus in those areas\\

We have locational data, so lets check for any geographical observation bias.
<<>>=
world <- map_data("world")
data %>% 
  select(Latitude, Longitude, Quantity, Location, `Material Description`) %>% 
  ggplot() +
    geom_polygon(data = map_data("world"), aes(x = long, y = lat, group = group), fill = "grey", alpha = 0.5) +
    geom_hex(aes(x = Longitude, y = Latitude), bins = 50) +
    scale_fill_viridis(trans = "log", breaks = c(5, 50, 500, 5000, 50000)) +
    theme_void() +
    guides(fill=guide_legend(title="Observations"))

#ggsave("plots/map.png", width = 20, height = 10, units = "cm")
@

We need to know how reliable the location data is. I'm going to filter for "united kingdom" in the location field and plot the raw coordinates.\\

\begin{figure}[H] %start a figure
\begin{center}
<<include= FALSE>>=
#Potentially remove
#Scatterplot of long/lat positions
#We have a outliers here. Maybe a difference in standards used for Longitude and Latitude? Some systems put the Latitude origin close to the UK
data %>% 
  mutate(Location = str_to_lower(Location)) %>% 
  filter(str_detect(Location, "united kingdom")) %>% 
  select(Latitude, Longitude) %>% 
  ggplot(aes(x = Latitude, y = Longitude)) +
    geom_point(position = "jitter")
@
\caption {Longitude and Latitude discrepancies}
\label{figJ}
\end {center}
\end {figure}


Questions\\
Distribution of plastic by location.\\
Are the distributions of plastic fairly constant for the locations with the most observations?\\
\begin{figure}[H] %start a figure
\begin{center}
<<>>=
#columnchart of debris locations
topLocations <- data %>% 
  group_by(Location) %>% 
  summarise(sumQuantity = sum(Quantity)) %>% 
  arrange(desc(sumQuantity)) %>% 
  top_n(5,sumQuantity)

data %>% 
  filter(Location %in% topLocations$Location) %>% 
  group_by(Location, `Material Description`) %>% 
  summarise(sumQuantity = sum(Quantity)) %>% 
  arrange(desc(sumQuantity)) %>% 
  ggplot(aes(x = `Material Description`, y = sumQuantity, fill = Location)) +
    geom_col() + theme(legend.position = 'top')
@
\caption {Debris by location}
\label{figG}
\end {center}
\end {figure}
We see that the Location "unknown" has the most plastic... note that this is distinct from "(Missing)", which was our original NA values. Maybe we should merge these.



\subsection{Item Pairing} 
(e.g. are 6-pack beer rings observed at the same time as fireworks? )
\hl{are we going to explore this one?}

\pagebreak
\section{Predictive Modelling}
Given the variability of plastic pollution trends given event-driven and location-driven pollution as explored earlier in this report, the authors of this report built a model to predict the proportion of plastics given Month and Location. This would give more accurate predictions as opposed to a simple linear model accomodating such time factored

\subsection{Description of Model}

Georgios' script
<<>>=

plasticN <- plastic %>% 
  mutate(month = month(Time, label = FALSE), year = as.integer(year(Time))) %>% 
  filter(year > 2010) %>% 
  group_by(year, category, month) %>%
  summarise(`Total Quantity` = sum(Quantity))



####


df11N <- plasticN  %>%
  filter(year == 2011) %>% 
  group_by(year, month) %>%
  mutate(freq = `Total Quantity` / sum(`Total Quantity`))

df12N <- plasticN  %>%
  filter(year == 2012) %>% 
  group_by(year, month) %>%
  mutate(freq = `Total Quantity` / sum(`Total Quantity`))


df13N <- plasticN  %>%
  filter(year == 2013) %>% 
  group_by(year, month) %>%
  mutate(freq = `Total Quantity` / sum(`Total Quantity`))


df14N <- plasticN  %>%
  filter(year == 2014) %>% 
  group_by(year, month) %>%
  mutate(freq = `Total Quantity` / sum(`Total Quantity`))

df15N <- plasticN  %>%
  filter(year == 2015) %>% 
  group_by(year, month) %>%
  mutate(freq = `Total Quantity` / sum(`Total Quantity`))


df16N <- plasticN  %>%
  filter(year == 2016) %>% 
  group_by(year, month) %>%
  mutate(freq = `Total Quantity` / sum(`Total Quantity`))



df17N <- plasticN  %>%
  filter(year == 2017) %>% 
  group_by(year, month) %>%
  mutate(freq = `Total Quantity` / sum(`Total Quantity`))


df18N <- plasticN  %>%
  filter(year == 2018) %>% 
  group_by(year, month) %>%
  mutate(freq = `Total Quantity` / sum(`Total Quantity`)) 

df19N <- plasticN  %>%
  filter(year == 2019) %>% 
  group_by(year, month) %>%
  mutate(freq = `Total Quantity` / sum(`Total Quantity`)) 


dfTotN <- rbind(df11N, df12N, df13N, df14N, df15N, df16N, df17N, df18N, df19N)

# plot for observing the data
(time_plotfr2N <- ggplot(dfTotN, aes(x = year, y = freq, color=category, fill = category)) +
  geom_smooth(method="lm", level=0.95) +
  theme_bw() + 
  xlab("Years") +
  ylab("relative frequency") +
  ggtitle("portion of plastic") + 
  expand_limits(y=0) +
  scale_y_continuous() + 
  scale_x_continuous()+
  theme(legend.position="bottom")+
  theme(legend.text = element_text(size=5, face="bold")))


#1/4/20
### MODELING with new categorisation


# create train and test set
n <- nrow(dfTotN)  # Number of observations
ntrain <- round(n*0.75)  # 75% for training set
set.seed(314)    # Set seed for reproducible results
tindex <- sample(n, ntrain)   # Create a random index
train_dfTotN <- dfTotN[tindex,]   # Create training set
test_dfTotN <- dfTotN[-tindex,]

# modelling for category "Cigarette related waste"

train_Cigrel <- train_dfTotN %>% 
  filter(category=="Cigarette related waste") %>% 
  group_by(year)

test_Cigrel <- test_dfTotN %>% 
  filter(category=="Cigarette related waste") %>% 
  group_by(year)

set.seed(1234)
train_Cigrel.modelN <- lm(freq ~ year, data = train_Cigrel)
summary(train_Cigrel.modelN)

print("PREDICTION")
pred_Cigrel <- predict(train_Cigrel.modelN, test_Cigrel)
summary(pred_Cigrel)

actuals_predsCigrel <- data.frame(cbind(actuals=test_Cigrel$freq, predicteds=pred_Cigrel)) 
head(actuals_predsCigrel)
correlation_accuracy <- cor(actuals_predsCigrel)
min_max_accuracy <- mean(apply(actuals_predsCigrel, 1, min) / apply(actuals_predsCigrel, 1, max))  
# => 53.73%, min_max accuracy
mape <- mean(abs((actuals_predsCigrel$predicteds - actuals_predsCigrel$actuals))/actuals_predsCigrel$actuals)
@

Pr( greater than |t|) is the p-value, defined as the probability of observing any value equal or larger than t if H0 is true. The larger the t statistic, the smaller the p-value. Generally, we use 0.05 as the cutoff for significance; when p-values are smaller than 0.05, we reject H0 that there's no difference between the means and conclude that a significant difference does exist. If the p-value is larger than 0.05, we cannot conclude that a significant difference exists.



time statistically significant

<<>>=
#1/4/20
# modelling for category "Food realted waste"
train_Foodrel <- train_dfTotN %>% 
  filter(category=="Food related waste") %>% 
  group_by(year)

test_Foodrel <- test_dfTotN %>% 
  filter(category=="Food related waste") %>% 
  group_by(year)

set.seed(1234)
train_Foodrel.modelN <- lm(freq ~ year, data = train_Foodrel)
summary(train_Foodrel.modelN)

print("PREDICTION")
pred_Foodrel <- predict(train_Foodrel.modelN, test_Foodrel)
summary(pred_Foodrel)

actuals_predsFoodrel <- data.frame(cbind(actuals=test_Foodrel$freq, predicteds=pred_Foodrel)) 
head(actuals_predsFoodrel)
correlation_accuracy <- cor(actuals_predsFoodrel)  # 5.31%
min_max_accuracy <- mean(apply(actuals_predsFoodrel, 1, min) / apply(actuals_predsFoodrel, 1, max))  
# => 53.73%, min_max accuracy
mape <- mean(abs((actuals_predsFoodrel$predicteds - actuals_predsFoodrel$actuals))/actuals_predsFoodrel$actuals)

# time statistically significant

#1/4/20
# modelling for category "Other"
train_Other <- train_dfTotN %>% 
  filter(category=="Other") %>% 
  group_by(year)

test_Other <- test_dfTotN %>% 
  filter(category=="Other") %>% 
  group_by(year)

set.seed(1234)
train_Other.modelN <- lm(freq ~ year, data = train_Other)
summary(train_Other.modelN)

print("PREDICTION")
pred_Other <- predict(train_Other.modelN, test_Other)
summary(pred_Other)

actuals_predsOther <- data.frame(cbind(actuals=test_Other$freq, predicteds=pred_Other)) 
head(actuals_predsOther)
correlation_accuracy <- cor(actuals_predsOther)  # 5.31%
min_max_accuracy <- mean(apply(actuals_predsOther, 1, min) / apply(actuals_predsOther, 1, max))  
# => 53.73%, min_max accuracy
mape <- mean(abs((actuals_predsOther$predicteds - actuals_predsOther$actuals))/actuals_predsOther$actuals)

# Time statistically not significant-pvalue too high

#1/4/20
# modelling for category "Plastic bags and Styrofoam packaging"
train_Plbag <- train_dfTotN %>% 
  filter(category=="Plastic bags and Styrofoam packaging") %>% 
  group_by(year)

test_Plbag <- test_dfTotN %>% 
  filter(category=="Plastic bags and Styrofoam packaging") %>% 
  group_by(year)

set.seed(1234)
train_Plbag.modelN <- lm(freq ~ year, data = train_Plbag)
summary(train_Plbag.modelN)

print("PREDICTION")
pred_Plbag <- predict(train_Plbag.modelN, test_Plbag)
summary(pred_Plbag)

actuals_predsPlbag <- data.frame(cbind(actuals=test_Plbag$freq, predicteds=pred_Plbag)) 
head(actuals_predsPlbag)
correlation_accuracy <- cor(actuals_predsPlbag)  # 5.31%
min_max_accuracy <- mean(apply(actuals_predsPlbag, 1, min) / apply(actuals_predsPlbag, 1, max))  
# => 53.73%, min_max accuracy
mape <- mean(abs((actuals_predsPlbag$predicteds - actuals_predsPlbag$actuals))/actuals_predsPlbag$actuals)


# Time statistically not significant-pvalue too high


#1/4/20
# modelling for category "Fragments"
train_Frag <- train_dfTotN %>% 
  filter(category=="Fragments") %>% 
  group_by(year)

test_Frag <- test_dfTotN %>% 
  filter(category=="Fragments") %>% 
  group_by(year)

set.seed(1234)
train_Frag.modelN <- lm(freq ~ year, data = train_Frag)
summary(train_Frag.modelN)

print("PREDICTION")
pred_Frag <- predict(train_Frag.modelN, test_Frag)
summary(pred_Frag)

actuals_predsFrag <- data.frame(cbind(actuals=test_Frag$freq, predicteds=pred_Frag)) 
head(actuals_predsFrag)
correlation_accuracy <- cor(actuals_predsFrag)  # 5.31%
min_max_accuracy <- mean(apply(actuals_predsFrag, 1, min) / apply(actuals_predsFrag, 1, max))  
# => 53.73%, min_max accuracy
mape <- mean(abs((actuals_predsFrag$predicteds - actuals_predsFrag$actuals))/actuals_predsFrag$actuals)


# Time statistically not significant-pvalue too high

@

In total we see that time is statistically significant in the change of proportions of certain categories of plastic waste, cigarette related waste and food related waste. This is not the case for the other 3 categories.This is supported by a paper that I sent to Roshi on Sunday where this situation is discussed. Some plastic waste
categories are time variant while others aren't and this has to do a  lot with sampling techniques and one-sidedness of datasets. It does not mean that the datasets are wrong it just shows even more that what we have talked about over many group meetings regarding the dataset being biased one way or the other is clearly backed by statistical evidence within this dataset and by referencial evidence too."

"Paper: Spatial and Temporal Patterns of Stranded Intertidal Marine Debris:
Is There a Picture of Global Change?"



\subsection{Model Evaluation}


\subsection{Model Results}




\pagebreak
\section{Discussion}

It was noted that the main system for reporting debris was used by large scale clobes. This means that data is not a continuous and even flow so during events such as international beach cleanup day there may be more data in the respective month. Since these events aim mostly to cleanup after big social events extra effort might have been made to retrive entertainment based debris such as fireworks, food packaging and six pack rings.The decrease in cigarette waste was observed to be in corelation with a decreesing smoking rate.


\section{Conclusion and Future Work}\label{cdsmote1}

Our hypothesis stands/does not stand.
The hypothesis H1 stands. This is no evident as to a change in the percentage of marine debris being plastic in origin that can be observed in results such as in figure 4.  
Future work might involve continuing to study corelations similar to the fireworks/july corelation.  



%Edit here 
%\blindtext[2]




\pagebreak
\section{Project Management}\label{mgt}
\subsection{Facilities}
Group 2 communicated using a dedicated Slack Channel, Github repository and weekly 1 hour meetings before the wednesday lab.
All project documents used and the final report can be accessed from the \textit{\href{https://github.com/KarenJewell/CMM507Group2}{Public Github Repository}}
\hl{obviously we need to mention the whole covid-19 thing and how we worked around it.}

\subsection{Project Progress}

% Pay attention to the code below including the chunk options 
<<results='asis'>>=
require(openxlsx);
require(readxl)
library(stringr);library(data.table)
library(XLConnect)
library(xtable)

# Sheets names 
fileName <- 'data/meetings.xlsx'
sheets <- readxl::excel_sheets(fileName)
#length(sheets)
# Read 1st sheet (you shouldn't have more than one sheet for this task)
# read sheet into dataframe, and rbind
dfs <- readWorksheet(loadWorkbook("data/meetings.xlsx"),sheet=1)
dfs$Date <-as.character(dfs$Date)
print(xtable(dfs,
                    caption = "Record of Team Meetings", 
                    label = "tab:one", 
                    table.placement = "", 
                    # align changes subject to number of columns 
                    align = "lllp{8cm}lllll"),include.rownames=FALSE,
                    caption.placement = "top")

    
@




\subsection{Peer-assessment}

<<results='asis'>>=
require(openxlsx);
require(readxl)
library(stringr);library(data.table)
library(XLConnect)
library(xtable)

# Sheets names 
fileName <- 'data/peers.xlsx'
sheets <- readxl::excel_sheets(fileName)
#length(sheets)
# Read 1st sheet (you shouldn't have more than one sheet for this task)
# read sheet into dataframe, and rbind
dfs <- readWorksheet(loadWorkbook("data/peers.xlsx"),sheet=1)

# convert fields into chars
dfs[, ] <- lapply(dfs[, ], as.character)

print(xtable(dfs,
                    caption = "Peer Assessment out of 100", 
                    label = "tab:two", 
                    table.placement = "", 
                    # align changes subject to number of columns 
                    align = "lllllll"),include.rownames=FALSE,
                    caption.placement = "top")

    
@


\pagebreak
\section*{References}\label{pubs}
\printbibliography[heading=none]

\end{document}
