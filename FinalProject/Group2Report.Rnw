\documentclass[10pt]{article}
\usepackage{graphicx, verbatim}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amscd}
\usepackage{lipsum}
\usepackage{blindtext}
\usepackage{todonotes}
\usepackage[tableposition=top]{caption}
\usepackage{ifthen}
\usepackage{caption}
\setlength{\textwidth}{6.5in} 
\setlength{\textheight}{9in}
\setlength{\oddsidemargin}{0in} 
\setlength{\evensidemargin}{0in}
\setlength{\topmargin}{-1.5cm}
\setlength{\parindent}{0cm}
\usepackage{setspace}
\usepackage{float}
\usepackage{fancyhdr}
\usepackage{tabularx}
\usepackage{soul} 

\usepackage{hyperref}
\hypersetup{
  colorlinks   = true, %Colours links instead of ugly boxes
  urlcolor     = blue, %Colour for external hyperlinks
  linkcolor    = blue, %Colour of internal links
  citecolor   = red %Colour of citations
}

\usepackage[backend=biber ,sorting=none]{biblatex}
\bibliography{references}
\begin{filecontents*}{references.bib}
\end{filecontents*}


%\fancyhf{}
\rfoot{Group 2 \thepage}
\singlespacing
\usepackage[affil-it]{authblk} 
\usepackage{etoolbox}
\usepackage{lmodern}

% \makeatletter
% \renewcommand{\maketitle}{\bgroup\setlength{\parindent}{16pt}
% \begin{flushleft}
%   \textbf{\@title}
% 
%   \@author
% \end{flushleft}\egroup
% }

%\renewcommand\Authfont{\fontsize{14}{18.4}\selectfont}
%\makeatother

% \pagestyle{fancy}
% \rfoot{Page \thepage}
 %\thispagestyle{empty} 

<<include=FALSE>>=
# Setting global chunk options
opts_chunk$set(
  eval = TRUE, 
  echo = TRUE, 
  message = FALSE, 
  warning = FALSE, 
  results='markup', 
  fig.width=6, 
  fig.height=2.5, 
  size="small", 
  out.width = "1\\linewidth", 
  tidy.opts=list(width.cutoff=60), 
  tidy=TRUE)

options(scipen=999)
# hides scientific notion, default back: options(scipen=0)
@


\begin{document}

\title{\LARGE Professional Development and Research Skills \\ CMM507 Coursework  \\ Group 2: Plastic Pollution in Oceans}

\author{ALEXANDER RITCHIE, \textit{\href{1911218@rgu.ac.uk}{1911218@rgu.ac.uk}};\\ GEORGIOS ORFANAKIS, \textit{\href{1903446@rgu.ac.uk}{1903446@rgu.ac.uk}};\\ KAREN JEWELL, \textit{\href{1415410@rgu.ac.uk}{1415410@rgu.ac.uk}};\\ ROSHI SHRESTHA, \textit{\href{1903445@rgu.ac.uk}{1903445@rgu.ac.uk}};\\ STUART WATT, \textit{\href{1501869@rgu.ac.uk}{1501869@rgu.ac.uk}}}

\maketitle
\noindent\rule{16cm}{0.4pt}


\section{Problem Statement}

\subsection{Overview}\label{over}

Marine pollution is a major global issue which impacts the environment, economy and human health. Although marine pollution is caused by many different materials, plastics consist of 60-80\% of the marine litter. \cite{DERRAIK2002} \cite{SMITH2013} \cite{KUO2014} \cite{ZHOU2011} \cite{JANG2014} Plastics are synthetic organic polymers and their lightweight feature and durability make it very suitable to make a range of products we use in our everyday life.\cite{BARNES2009} \cite{SIVAN2011} These same features are what makes plastic a major component of pollution, due to overuse and non-managed waste disposal systems internationally, contributing to 10\% of the waste generated worldwide.\cite{BARNES2009} As the global production of plastic increases, so does the problem in the marine environment. Due to its buoyancy, plastic debris can be dispersed over long distances and accumulate on the shorelines, even polluting the most remote areas \cite{LAVERS2017}. Jambeck et al.,\cite{JAMBECK2015} reported that in 2010 alone, between 4.8 million and 12.7 million metric tons of plastics entered the ocean. Plastics are everywhere in the marine environment and urgent action is required to mitigate this problem and reduce its harmful impact.\cite{RIOS2007} \cite{ROCHMAN2015} \\



\subsection{Motivation}\label{mot}

The impact of plastic pollution on marine life has been reviewed extensively. \cite{GALL2015} \cite{KUHN2015} \cite{RYAN2015} \cite{WILLIAMS2019} Over 700 marine wildlife species are affected due to entanglement in plastic ropes or materials, and from ingestion of plastics in the ocean.\cite{GALL2015} Over time, plastic disintegrates into microplastics and nanoplastics which are easily consumed by fish and enter the human food chain. Plastics have been found in a third of fish caught in the UK which included popular fish such as cod, haddock, and mackerel.\cite{LUSHER2013} The impact and effects of plastic entering the human food chain are still being studied, but plastic toxicity and the occurrence of microplastics and nanoplastics in the water supply also directly impacts human health, in addition to the contamination of seafood.\cite{ROCHMAN2015} \cite{MARKIC2020} \\

Although plastic litter has been a major cause of marine pollution for a while, its seriousness has only been realised recently and reducing plastic pollution has become a global aim. Research on plastic pollution in marine environments has played a big role in efforts to reduce it as well as in raising awareness globally. In order to understand plastic pollution in marine environments and its effects in the long term, it is essential to keep collecting data on patterns of marine debris around the world. Effective monitoring of plastic debris is essential to reducing the abundance of plastic debris everywhere. In addition, monitoring the type, frequency and the source of the litter is also important for marine pollution prevention initiatives. Most monitoring is done by survey, where organisations and volunteers record the types and frequencies of litter observed on the shoreline.\cite{COE1997} To understand the depth of the problem, it is essential to understand the amount and composition of marine litter. This can help in applying various mitigation strategies.\\

\subsection{Objectives }\label{obj}

The main objectives of this project is outlined as follows:
\begin{itemize}	
\item To review available literature on marine plastic problems and their impacts
\item To look at a suitable dataset to understand the composition of marine plastic pollution 
\item To create a linear regression model to predict the relevant frequency of distinct plastic debris categories over time
\item To present the derived results and conclusions 

\end{itemize}





























\pagebreak
\section{Research}\label{research}

An integral part of this report required a literature search to identify how researchers have been trying to monitor marine pollution and find the problems associated with it. Several studies have reported the abundance of plastic as marine litter through scientific survey and citizen science methods. A 12-year observation of coastal debris pollution using citizen science in Taiwan revealed that most debris items found were plastic. \cite{WALTHER2018} 19 categories of debris items were collected during the clean-up events and the five most commonly recorded debris categories were: plastic shopping bags, plastic bottle caps, disposable tablewares, fishing equipment, and plastic drinking straws. In a study covering western Japan and the eastern coasts of Russia \cite{KUSUI2003}, it found that 55\% to 93.4\% of items over the Japanese shores were plastic, and the second most abundant item was resin pellet which is also a form of plastic. On the eastern Russian coast, plastic items were also the most abundant, contributing to approximately 55\% of all litter, mostly of plastic fragments. The composition of litter was similar in the two countries, although the proportion of plastics was much higher in Japan. \cite{KUSUI2003} Further along the Asian upper east coast, hard plastic and styrofoam were the dominant plastic types found on Korean beaches. On average, hard plastic and styrofoam comprised 32\% and 48.5\% of the total debris count respectively. \\

In an older study over the Caribbean region, the most common types of debris found on the Caribbean coast of Panama were plastic and styrofoam, with the plastics being household or consumer related. Styrofoam packing materials were also abundant and may have come from trans-shipment activities of Colon's Free Zone, household waste, or offshore activity \cite{GARRITY1993}. A 2016/2017 annual study of 8 beaches in Tenerife in the Canary Islands also found that plastic was the most abundant litter there. They also reported that there was more accumulated plastic debris in remote beaches compared to the beaches near the city indicating the movement of debris. However, more long term study is required to understand the changes in the results reported over time. \cite{REINOLD2020} \\

It was observed by the authors of this report, that there were variations in how studies of litter accumulation had been conducted. The variations are present in the time span of the research, the parts of the coast from which litter was collected, as well as in the categorisation of litter, which creates difficulty when researchers want to compare different studies. The plastic pollution problem essentially requires the ability to assess changes in accumulation rates and composition, trends over time, and the effectiveness of management systems, which is a hard task without good monitoring methodologies. Although monitoring of marine litter is currently carried out within a number of countries around the world, the methods of survey and monitoring used tend to be very different, preventing comparisons and harmonisation of data across regions or time. \\

This is why the scientific community has been trying to create some common ground, which has led to initiatives joined by many countries worldwide. One of these initiatives, and probably the most important, is the International Clean Coast (ICC) program which is a new, long term approach to cleaner beaches using various activities to increase public awareness. \cite{ CHESHIRE2009} This initiative aims to develop a comprehensive litter characterisation scheme that uses both material composition and form. This allows Litter Monitoring Repeated (LMR) surveys of beaches, seabeds and/or surface waters to determine litter quantities such that information can be compared with baseline data to identify if changes occur over time or in response to management arrangements. \\

The ICC uses specifically developed categorisations of coast litter, with the most accepted being the Clean Coastal Index (CCI) protocol specific to the operational clean-up of beaches, which is useful for its simplicity and information provided, allowing comparisons between different times and places. The CCI is the recommended tool for evaluation of actual coast cleanliness, measuring plastic debris as an indicator of beach cleanliness, precluding bias by the assessor. The CCI also proved to be a useful tool for measuring progress and the success of activities in raising awareness among the general public. \cite{ALKALAY2007} \\

A study in Israel using the CCI protocol for categorisation found that plastic was the most ubiquitous beach litter item. An important contribution to this study was the ability to compare its findings to other Mediterranean beaches, showing that plastic was the dominant pollutant in the region, and non-plastic litter being highly specific to the region and cannot be treated universally. \cite{PORTMAN2017} In another study on litter pollution in a region of India, once again following the CCI protocol for the categorisation of litter, found that plastic was the main form of litter at approximately 45\% of total litter. Plastic bags topped the index at 33\%, followed by food wrappers, then plastic cups, and cigarette/cigar tips amounting to 5.5\%. \cite{KUMAR2016} The use of the common protocol in these two studies allowed researchers to compare their findings and create common plastic pollution models, even though the two coasts are continents apart. \\

Another study conducted in Cadiz, on the other side of the Mediterranean from Israel, found that plastic bottles and containers were the most frequent littered items, followed by plastic bags. This research also pointed out that surveys are heavily affected by clean-ups performed at beaches. \cite{WILLIAMS2016} Even though this study reaches important conclusions on the correct ways to clean coasts, it cannot be easily compared, or its conclusions easily applied without any standardised protocol. \\

From this review, it is evident that there have been many studies conducted to monitor marine pollution in various different ways. One of the most cost effective and efficient ways is the use of citizen science, where the general public can record any observations of marine litter \cite{EARP2019} and has beens been successfully used in many studies. \cite{ROY2012} \cite{FORRESTER2015} This method is also gaining popularity in marine pollution monitoring \cite{BRAVO2009} \cite{CARSON2012} \cite{HIDALGORUZ2017} \cite{BAUERCIVIELLO2018} and has also been assessed as a tool to increase awareness of the marine litter problem. \cite{LOCRITANI2019} \\


As discussed before, observations not following a standard protocol with proper guidance could be incomparable and rendered ineffective. The Marine Debris Tracker (MDT) is a joint initiative between National Oceanic and Atmospheric Administration (NOAA) Marine Debris Program (MDP) and the Universities of Georgia, North Carolina and South Carolina \cite{JAMBECK2015B}. The MDT allows anyone to record the marine debris observed, using an application on a mobile phone. The only report using data from this application is a web-based report by Tablada in 2018 \cite{JAMBECK2015B}, where data analysis was performed on 8 years of the data mainly focused in North America. The study also concluded that plastic was the main type of debris recorded, with cigarettes being the top identified littered item. The subsequent sections of this report will aim to contribute to this body of knowledge, using the worldwide coastal littering dataset from the MDT, with an interest in identifying if plastic is indeed the most abundant litter of the worldwide dataset, which would be in agreement with the various studies discussed in this review. Following which, this report will analyse the distribution of subclasses within the plastics found, and explore if there could be a way to computationally monitor and assess the coastal littering problem, using the established CCI categorisation of litter. \\








\pagebreak
\section {Methods}\label{methods}

\subsection{Data Description}\label{dataset}

The data used in this report was gathered using secondary data collection methods only. The authors did not collect or create any new data using primary methods. The data was downloaded from the Marine Debris Tracker website (\url{www.marinedebris.engr.uga.edu}) on 19 February 2020. The dataset is composed of 363,368 global observations from the start of the program in 2010, to the latest available date at the time of download. \\

As discussed in the section before, the MDT is a citizen science project where organisations or individuals can record observations of marine debris using a mobile phone application. \cite{JAMBECK2015B} The user records the observation using a structured form, and chooses the category of debris from a list provided but there are also multiple available fields to populate, including non-mandatory fields and some allowing free text entry. An example of a non-mandatory field are "Lists" which are customisable groupings usually for organisations to group their own collection of records.The table below describes the structure of the data. 

\begin{table}[H]
\begin{tabular}{ l l l }
Field & Description & Type \\
\hline
ListName & custom groupings of records & Non-mandatory \\
ListID & ID for ListName & Automated \\
ItemName & the category of debris & Mandatory \\
ItemID & ID for ItemName & Automated \\
LogID & unique ID for the observation & Automated \\
Quantity & the number of pieces of debris observed & Mandatory \\
Error radius & radius around the site within the error for reasonable doubt & Mandatory \\
Latitude & coordinates of the location where the observation was made & Mandatory \\
Longitude & coordinates of the location where the observation was made & Mandatory \\
Altitude & coordinates of the location where the observation was made & Mandatory \\
Location & text description of the location where the observation was made & Mandatory \\
Description & open text description for the observation & Non-mandatory \\
MaterialDescription & the material of the debris & Mandatory \\
MaterialID & ID for MaterialDescription & Automated \\
Timestamp & the date and time of observation & Mandatory \\
\end{tabular}
\end{table}



\pagebreak
\subsection{Data Pre-processing}\label{preprocessing}

<<>>=
# Setting the environment
library(tidyverse)
library(purrr)
library(magrittr)
library(treemap)
library(hexbin)
library(mapdata)
library(viridis)
library(lubridate)
library(imager)
library(xtable)
library(dplyr)

# Loading the data
data <- list.files(path = "data/debris/", full.names = TRUE) %>% 
  lapply(FUN = read_csv, col_types = "ififidddddcfcif") %>% 
  reduce(rbind)

# Checking the size of the data
cat("rows: ", nrow(data),"; columns: ", ncol(data))
@



From download, the data was cleaned to prepare it for analysis. First, the \textbf{Timestamp} datetime information was converted into a date type format and renamed as variable \textbf{Time}

<<>>=
# Replacing the column for time as a date data type, renaming it "Time" 
data$Time <- data$Timestamp %>% 
  parse_datetime(format = "%Y%m%d%H%M%S")
data$Timestamp <- NULL
@


The dataset was then inspected for missing values which were observed in the \textbf{Location} and \textbf{Description} fields, but as these are non-mandatory and open text fields it is to be expected, and all other fields are complete.\\ 
<<>>=
# Identifying missing values
data %>% select_if(function(x) any(is.na(x))) %>% colnames()
@

It was observed that observations were incomplete for years 2010, 2011 and 2020, and so it was decided to retain only complete years of information for fair and standard comparisons.
<<>>=
# Count the number of months in each year
data %>% 
  mutate(year = year(Time),
         months = month(Time)) %>% 
  select(year, months) %>%
  unique() %>%
  group_by(year) %>% 
  summarize(nmonths = n())
@

<<>>=
# Filter for observations occuring between the years 2012-2019 inclusive
data <- data %>% filter(as.integer(year(Time)) %in% 2012:2019)
@

<<>>=
# Checking the size of the data
cat("rows: ", nrow(data),"; columns: ", ncol(data))
@

Assessing the dataset for unique items it was observed that there are 8 material categories containing 55 different item subcategories and with them 7982 unique descriptions across the 349,556 observations. 
<<results='asis'>>=
# Counting unique values in fields
data %>% 
  summarise_all(~length(unique(.))) %>% 
  pivot_longer(cols = everything(), 
               names_to = "Field", 
               values_to = "Unique Values") %>% 
  arrange(desc(`Unique Values`)) %>% 
  xtable(caption = "The count of unique values in fields", 
         label = "tab:unique", 
         caption.placement = "top",
         floating=TRUE,
         type="latex",
         table.placement = "H")
@

It is difficult to determine exactly how many global locations are observed in this dataset as it is the combination of \textbf{Longitude}, \textbf{Latitude}, \textbf{Altitude} and/or \textbf{Location} which determines the global position of the observation. Yet in \hyperref[fig1]{Figure 1} it is evident that the dataset is global, yet with a heavy influence of observations recorded in North America. It is also possible to identify that while most observed locations are on the coastline, some make reference to the middle of oceans and some are inland, which would account for pollution also observed in rivers and freshwater marine environments like lakes and natural reservoirs.

\begin{figure}[H] 
\begin{center}
<<fig.height=3>>=
# Map of all observed locations
world <- map_data("world")
data %>% 
  select(Latitude, Longitude) %>% 
  ggplot() +
    geom_polygon(data = map_data("world"), 
                 aes(x = long, y = lat, group = group), 
                 fill = "grey", alpha = 0.5) +
    geom_hex(aes(x = Longitude, y = Latitude), bins = 50) +
    scale_fill_viridis(trans = "log", breaks = c(5, 50, 500, 5000, 50000)) +
    theme_void() +
    guides(fill=guide_legend(title="Observations")) +
    theme(plot.title = element_text(size=10),
      text = element_text(size=8),
      panel.grid.major = element_blank(), 
      panel.grid.minor = element_blank(),
      legend.position = "bottom")
@
\caption {Observations by location}
\label{figG}
\end {center}
\end {figure}


\pagebreak
\subsection{Quantities}\label{quantities}

In exploring the dataset, it was noted that there was a highly skewed distribution of \textbf{Quantities} recorded per observation.

\begin{figure}[H] 
\begin{center}
<<>>=
# Scatter plot showing distribution of observation quantities
data %>% 
  mutate(Year = as.integer(year(Time))) %>%
  select(Quantity, Year) %>%
  group_by(Quantity, Year) %>%
  summarise(density = n()) %>%
  ggplot(aes(x=Quantity, y=density)) + 
    geom_point() +
    scale_x_continuous(trans = 'log10', name='Quantity Recorded in Observation') +
    scale_y_continuous(name='Number of Observations') +
    theme_bw() +
    theme(text = element_text(size=8),
          panel.grid.major = element_blank(), 
          panel.grid.minor = element_blank())
@
\caption {Distribution of quantities recorded by number of observations recording them}
\label{fig2}
\end {center}
\end {figure}

\hyperref[fig2]{Figure 2} demonstrates the variance in the quantities by each observation in the dataset, and the frequency at which those quantities were recorded. It is easy to see the right-skew which indicates that the vast majority of the 300 thousand observations recorded quantities of  0 to 10, yet the minority record quantities varying between 10 and 100,000.\\

<<results='asis'>>=
# Identifying observations with the largest 10 quantities
data %>%
  mutate(Year = as.integer(year(Time))) %>%
  select(`Material Description`,ItemName,Year,Description,Quantity) %>%
  arrange(desc(Quantity)) %>%
  head(10)%>%
  xtable(caption = "Observations with the 10 largest quantities", 
         label = "tab:top10quantities", 
         caption.placement = "top",
         align = "lp{1.5cm}p{2.5cm}lp{7cm}l",
         floating=TRUE, 
         type="latex", 
         table.placement="H")
@

<<results='asis'>>=
# Identifying quantity percentiles
percent_quantity <- 
  function(x){paste0(signif(length(data$Quantity[data$Quantity<=x])
                            /length(data$Quantity)*100, digits = 4), "%")}

tibble(Quantity = c("<=1","<=10","<=100"), 
       ObservationProportion = c(percent_quantity(1),
                                 percent_quantity(10),
                                 percent_quantity(100))) %>%
  xtable(caption = 
           "Proportion of observation having equal or less than the stated Quantity", 
         label = "tab:pquantities", 
         caption.placement = "top",
         floating=TRUE, 
         type="latex", 
         table.placement="H")
@

Looking further into the distribution, 99.6\% of all entries have observed quantities below 100, 96\% as 10 or fewer and 76\% as 1 item observed, suggesting that the vast majority of entries are citizen science entries. Interestingly some quantities are marked as 0, and there are a few observations with large quantities observed, possibly as a result of organised or research activity. In particular there are 5 observations with quantities of $>10,000$ recorded in 2012, 2013, 2015 and 2019. It was decided not to exclude these high quantity observations as it would exclude a wealth of information gathered by organised groups or studies. Instead for the majority of this report, the count of observations is deemed to be a fairer indicator of density, rather than the quantity which is influenced heavily by the high quantity counts.

\pagebreak
\subsection{Categorisation}

It is worth noting that of the 8 material categories, one is an "Other" category which allows users to categorise an item as such, if it is not appropriate for any other option on the list.

<<results='asis'>>=
# Listing of material categories
data %>% select(`Material Description`) %>%
  unique() %>%
  arrange(`Material Description`) %>%
  xtable(caption = "Listing of Material Descriptions", 
         label = "tab:materials", 
         caption.placement = "top",
         floating=TRUE, 
         type="latex", 
         table.placement="H")
@


A data quality check performed on assessing the debris subcategories were unique by material type, highlighted that the subcategory "Rubber Gloves" was associated with two material types, Plastic and Rubber. Yet otherwise, a one to many relationship exists between the parent material type and their item subcategories suggesting the integrity of the data remains intact.

<<>>=
# Checking for subcategory uniqueness
data %>% 
  select(`Material Description`, ItemName) %>%
  distinct() %$% 
  table(ItemName) %>% 
  as_tibble() %>% 
  filter(n > 1)
@


Further investigation into the categorisation of Rubber Gloves revealed that the majority of Rubber Glove items were classified as plastic rather than rubber. When the observation descriptions were considered however, it revealed that the categorisations may be innaccurate, for example where an observation had "Balloon" recorded in the description which is quite clearly not a glove. This raised the question of why these items were not classified as "Other" materials but wrongly labelled as Rubber Gloves, which is perhaps a downside and reflective of the inconsistencies which can occur in citizen science data gathering. 

<<results='asis'>>=
# Checking material categorisation of Rubber Gloves
data %>% select(`Material Description`, ItemName, Quantity) %>%
  filter(ItemName == "Rubber Gloves") %>% 
  group_by(`Material Description`) %>% 
  summarise(Quantity = as.integer(sum(Quantity))) %>%
  xtable(caption = "Material categorisation of Rubber Gloves", 
         label = "tab:2", 
         caption.placement = "top",
         floating=TRUE, 
         type="latex", 
         table.placement="h")


# Checking the descriptions of Rubber Glove items
data %>% select(`Material Description`, ItemName, Description) %>%
  filter(ItemName == "Rubber Gloves", !is.na(Description)) %>%
  distinct() %>%
  xtable(caption = "Descriptions of Rubber Glove items", 
         label = "tab:3", 
         caption.placement = "top",
         floating=TRUE, 
         type="latex", 
         table.placement="h")
@


\begin{figure}[H] 
\begin{center}
<<>>=
# Line chart showing categorisation of Rubber Gloves over time  
data %>% 
  filter(ItemName == "Rubber Gloves") %>%
  mutate(months = floor_date(Time, 'month')) %>% 
  group_by(months, ItemName,`Material Description`) %>% 
  summarize(`Number of observations` = n()) %>% 
  ggplot(aes(x = months, y = `Number of observations`)) +
    geom_line(aes(color=`Material Description`)) +
    theme_bw() +
    theme(panel.grid.major = element_blank(), 
          panel.grid.minor = element_blank(),
          legend.position = "bottom")
@
\caption {Categorisation of Rubber Glover over Time}
\label{figE1}
\end {center}
\end {figure}

However when the Rubber Glove categorisation was considered over time, it became apparent that in September 2019, the first use of "Rubber" to classify Rubber Gloves appeared as did the the last categorisation as "Plastic" at the same time. This suggests that the material classification was potentially changed at this time, which explains the two material categories and is not in fact an indicator of poor quality data.\\


\pagebreak
\subsection{Recategorisation}\label{recategorisation}

The \textbf{ItemName} subcategories of the Plastic type were recategorised following the CCI protocol to allow for consistency and comparability across studies as has been discussed in \hyperref[research]{Section 2}.\\

25 \textbf{ItemNames} were recategorised as below:
\begin{itemize}
\item "Cigarettes", "Cigarette or tobacco packaging" and "Cigar Tips" as: Cigarette related waste
\item "Straws", "Bottle or Container Caps", "Food Wrappers", "Beverage Bottles", "Foam or Plastic Cups", "Six-pack rings", "Hard plastic fragments" and "Plastic utensils" as: Food related waste
\item "Toys (plastic", "Ballons - Mylar", "Personal care products", "Other jugs or Containers", "Fireworks", "Chemicals and chemical containers", "Non-food related plastic packaging" and "Rubber Gloves" as: Non food related waste
\item "Plastic Bags" and "Styrofoam packaging" as: Plastic bags and Styrofoam packaging
\item "Plastic or Foam Fragments", "Hard plastic fragments", "Foam fragments" and "Film Fragments" as: Fragments
\end{itemize}


<<eval=FALSE, echo=FALSE>>=
# Probably remove
plastic_ordered <- data %>% 
  filter(`Material Description` == "PLASTIC") %>% 
  select(ItemName, Quantity) %>% 
  group_by(ItemName) %>% 
  summarise(Total = sum(Quantity)) %>% 
  arrange(desc(Total))
@


<<>>=  
# Recategorisation of all plastic items by CCI categories

# all cigarette related waste: 1, 4, 6, 22
# Food related waste: 3, 2,7,9,10, 17, 23, 11
# Non food related waste: 8, 14, 15, 16, 18, 19, 21, 20
# Plastic bags and Styrofoam packaging:12, 13
# Fragments: 5, 23, 24,25

recategorise <- function(x){
  out = ""
  if(x %in% c(3,15,9,22)){out = "Cigarette related waste"}
  if(x %in% c(6,11,8,5,10,4,23,14)) out = "Food related waste"
  if(x %in% c(17,7,13,21,1,16,20,19)) out = "Other"
  if(x %in% c(2,18)) out = "Plastic bags and Styrofoam packaging"
  if(x %in% c(12,23,24,25)) out = "Fragments"
  if(out == "") stop(paste("Error in recategorise:", x))
  return(out)
}

plastic_types <- data %>% 
  filter(`Material Description` == "PLASTIC") %>% 
  select(ItemName, ItemID) %>% 
  distinct() %>% 
  mutate(label = 1:n()) %>% 
  mutate(category = purrr::map(label, recategorise)) %>%
  mutate(category = as_factor(as.character(category))) %>% 
  select(ItemID, category)


plastic <- data %>% 
  filter(`Material Description` == "PLASTIC") %>% 
  full_join(plastic_types, by = "ItemID")

@

\begin{figure}[H]
\begin{center}
<<fig.height=4>>=
plastic %>% 
  mutate(month = month(Time, label = FALSE), 
         year = as.integer(year(Time))) %>% 
  group_by(month, year, category) %>%
  summarise(`Total Quantity` = sum(Quantity)) %>% 
  ggplot(aes(x = month, y = `Total Quantity`, fill = category)) +
    geom_col(colour = "black", size = 0.2, position = "fill") +
    facet_wrap(~year, nrow = 2) +
    scale_fill_viridis(discrete = TRUE, option = "plasma") +
    xlab("Month") +
    ylab("Proportion of Items") +
    scale_x_continuous(breaks = 1:12) +
    theme(panel.grid.major.x = element_blank(),
          panel.grid.minor.x = element_blank(),
          legend.position = "bottom",
          legend.text=element_text(size=5)) + 
    guides(fill=guide_legend(title="Category"))
@
\caption {Relative frequencies of observed plastic waste by category}
\label{figB}
\end {center}
\end {figure}


These charts display the proportion of plastic debris using the new categories, and in having a smaller variety of categories makes it easier to identify changes over the period.















\pagebreak
\section{Experiments}



\subsection{Proportion Trends}
% The key variable in this section is TIME (Years, Months)
After cleaning and recategorisation of the data, it was analysed to determine how pollutant proportions change over time.\\



Per the data, an increase can be seen in debris observed over time. However, caution must be exercised in interpreting this information, as this increase may be reflective indeed of increased pollution levels, but it could also be because of increased activity in the citizen science project as it matures and gains a larger user base.\\

\begin{figure}[H] 
\begin{center}
<<>>=
# Line chart of observations: Total v Plastic
data %>% 
  mutate(Type = if_else(`Material Description` == "PLASTIC", "Plastic", "Other"),
         months = floor_date(Time, 'month')) %>% 
  group_by(months, Type) %>% 
  summarize(`Number of observations` = n()) %>% 
  ggplot(aes(x = months, y = `Number of observations`, colour = Type)) +
    geom_line() +
    theme(legend.position = "bottom")
  
@
\caption {Observations of plastic debris v all debris}
\label{figF}
\end {center}
\end {figure}

In this chart we see peaks and troughs in the number of observations which is indicative of change in the rate of user activity. Seeing the peak in 2013 and more of these spikes in 2017, 2018 and 2019, but generally it is an increasing trend in monitoring activity.\\


\begin{figure}[H] 
\begin{center}
<<>>=
# Column plot of average daily observations by year
data %>%
  mutate(Date = date(Time)) %>% 
  full_join(tibble(Date = full_seq(c(min(date(data$Time)), 
                                     max(date(data$Time))), 
                                   period = 1)), by = "Date") %>% 
  group_by(Date) %>% 
  summarise(Observations = length(LogID)) %>% 
  ungroup() %>% 
  mutate(Year = lubridate::year(Date)) %>%
  group_by(Year) %>% 
  summarise(Average_Daily_Observations = mean(Observations)) %>% 
  ungroup() %>% 
  ggplot(aes(x = Year, y = Average_Daily_Observations)) +
    geom_col() +
    xlab("Year") +
    ylab("Average Daily Observations") +
    scale_x_continuous(breaks = 2012:2019) +
    theme_bw() +
    theme(text = element_text(size=8),
          panel.grid.major = element_blank(), 
          panel.grid.minor = element_blank())
@
\caption {Average Daily Observations by Year}
\label{figD1}
\end {center}
\end {figure}

Looking at the increasing number of average observations per day lends support to the theory that the increase in quantity observations is factored by increase in citizen science monitoring activity. That's not to say pollution has not also increased in this period, but it would be inaccurate to not account for the increase in monitoring activity.\\


\begin{figure}[H] 
\begin{center}
<<>>=
# Column chart showing % distribution of material types
data %>% 
  mutate(Year = lubridate::year(Time)) %>% 
  group_by(Year, `Material Description`) %>% 
  summarise(Counts = n()) %>% 
  ungroup() %>% 
  ggplot(aes(x = Year, y = Counts, fill = `Material Description`)) +
    geom_col(colour = "black", size = 0.2, position = "fill") +
    scale_fill_hue(l=50, c=150) +
    scale_x_continuous(breaks = 2012:2019) +
    scale_y_continuous(labels=scales::percent, name="") +
    theme_bw() +
    theme(text = element_text(size=8),
          panel.grid.major = element_blank(), 
          panel.grid.minor = element_blank(),
          legend.position = "bottom")

@
\caption {Proportion of Debris by Material Types}
\label{fig1}
\end {center}
\end {figure}

Analysis of the poportions of pollutant materials identifies that plastic is the dominant marine pollutant material, and its majority proportion of total debris is relatively consistent year on year. This could be due to an increase in new plastic pollution entering marine environments from source, not helped by the fact it is durable and does not decompose quickly, or that the other pollutant materials are decreasing. This analysis therefore is in agreement with the studies discussed in \hyperref[research]{Section 2} that plastic is indeed the biggest problem in marine pollution accounting for approximately 70\% of all marine pollution. 




\begin{figure}[H] 
\begin{center}
<<>>=
# Line of just Plastic
data %>% 
  mutate(Year = lubridate::year(Time)) %>% 
  group_by(Year, `Material Description`) %>% 
  summarise(total = n()) %>%
  mutate(prop = total / sum(total),lab=scales::percent(prop)) %>%
  filter(`Material Description`=="PLASTIC") %>%
  ggplot(aes(x = Year, y = prop, label = lab))+
  geom_text(nudge_y = 0.05, color = "black") + 
  geom_line(aes(x = Year, y = prop))+
  geom_point(aes(x = Year, y = prop)) +
  scale_y_continuous(labels=scales::percent, name="", limits = c(0, 1)) +
  theme_bw() +
  theme(text = element_text(size=8),
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        legend.position = "bottom")

@
\caption {Trend of Plastic as a proportion of Total Debris}
\label{figF}
\end {center}
\end {figure}

When considering the charts above, it can be determined that even as total debris observations increase, so do plastic observations which means plastics remain a consistently common feature of the observed derbis over time.\\

\begin{figure}[H] 
\begin{center}
<<fig.height=6>>=
data %>% 
  filter(`Material Description` == "PLASTIC") %>% 
  mutate(year = as.integer(year(Time))) %>% 
  group_by(year, ItemName) %>%
  summarise(total = n()) %>% 
  mutate(prop = total / sum(total),lab=scales::percent(prop)) %>%
  ggplot(aes(x = year, y = prop)) +
    geom_line() +
    scale_y_continuous(labels=scales::percent, name="% of Total Plastic") +
    facet_wrap(~ItemName, nrow = 5) +
    theme(text = element_text(size=6),
          axis.text.x=element_text(angle=45, hjust=1),
          axis.ticks.y = element_blank(),
          axis.title.x = element_blank(),
          axis.title.y = element_blank())
@
\caption {Proportion of Plastic Items Over Time}
\label{figF4}
\end {center}
\end {figure}


As these charts consider the proportion of the subcategory item of total plastics, it is important to note that the increase in Plastic or Foam fragments and Food Wrappers might be attributed actually to a decrease in other subcategories such as Cigarettes. Essentially, not that these items are becoming increasingly common, but that the share between them is levelling. Considering the discussions above, it should be recalled that all debris and plastic are being increasingly observed, so a decrease in a subcategory item is welcomed yet more must be done. To explain the decrease, it is possible that better waste management practices for cigarettes have been put into place, for example the introduction of penalties for literring cigarette butts or installing better cigarette butt collection points in high activity areas, resulting the decrease of observations witnessed here. It could however also be influenced by changes in social patterns such as persons smoking less or moving to reusable portable vaping devices which result is the lower consumption of single-use cigarettes and the resulting debris. Eitherway, being able to view key subcategories like this allows researchers to identify where to focus their efforts to ultimately achieve the aim of reducing pollution. 

\pagebreak
\subsection{Event-Driven Pollution}

An interesting pattern which emerged when conducting exploratory analysis on the data, were peaks in the observations of debris classified as Fireworks consistently in July.\\

\begin{figure}[H] 
\begin{center}
<<>>=
# Boxplot of fireworks distribution by month (across all years)
data %>% 
  filter(`Material Description` == "PLASTIC",
         ItemName %in% c("Fireworks")) %>%
  mutate(month = month(Time, label = TRUE), 
         year = as.integer(year(Time))) %>% 
  group_by(month, year) %>% 
  summarise(Observed = n()) %>% 
  ggplot() +
    geom_boxplot(aes(x = month, y = Observed)) +
    xlab("Month") +
    ylab("Observed") +
    theme_bw() +
    theme(text = element_text(size=8),
      panel.grid.major = element_blank(), 
      panel.grid.minor = element_blank(),
      legend.position = "bottom")
@
\caption {Firework debris 2012-2019}
\label{figA1}
\end {center}
\end {figure}

Given that it is known the dataset carries a heavy North American influence, a theory emerged that the peaks of observed debris were possibly related to American 4th of July celebrations. Looking at the locations of the firework observations in thevisualisation below certainly seemed to support that as firework related observations were made mostly in North America with a small sample in the United Kingdom. Interestingly, no spikes are observed in January which might suggest New years' celebrations, or in November for Bonfire Night celebrations on the 5th of November in the UK.\\

This gives rise to the idea that plastic pollution while sometimes blamed to be the effect of manufacturing processes, can also be largely driven by the disposable behaviours which humans encourage in these one off-events. Where the items are not intended for repeated use, used once and discarded, and eventually becoming pollutants in marine environments.


\begin{figure}[H] 
\begin{center}    
<<fig.height=3>>=
# Map of locations having observed firework debris
data %>% 
  filter(ItemName == "Fireworks") %>%
  select(Latitude, Longitude) %>% 
  ggplot() +
    geom_polygon(data = map_data("world"), 
                 aes(x = long, y = lat, group = group), 
                 fill = "grey", alpha = 0.5) +
    geom_hex(aes(x = Longitude, y = Latitude)) +
    theme_void() +
    guides(fill=guide_legend(title="Observed")) +
    theme(plot.title = element_text(size=10),
      text = element_text(size=8),
      panel.grid.major = element_blank(), 
      panel.grid.minor = element_blank(),
      legend.position = "bottom")
@

\caption {Boxplot of fireworks distribution by month, across all years}
\label{figA2}
\end {center}
\end {figure}



\pagebreak
\section{Predictive Modelling}
Given the variability of plastic pollution trends given event-driven and location-driven pollution as explored earlier in this report, the authors of this report built a model to give more accurate predictions of expected pollution levels which can be used as a base model to assess the effectiveness of pollution reducing initiatives introduced by various organisations.

\subsection{The Model}

<<>>=

plasticN <- plastic %>% 
  mutate(month = month(Time, label = FALSE), 
         year = as.integer(year(Time))) %>%  
  group_by(year, category, month) %>%
  summarise(`Total Quantity` = sum(Quantity))

####

df12N <- plasticN  %>%
  filter(year == 2012) %>% 
  group_by(year, month) %>%
  mutate(freq = `Total Quantity` / sum(`Total Quantity`))

df13N <- plasticN  %>%
  filter(year == 2013) %>% 
  group_by(year, month) %>%
  mutate(freq = `Total Quantity` / sum(`Total Quantity`))

df14N <- plasticN  %>%
  filter(year == 2014) %>% 
  group_by(year, month) %>%
  mutate(freq = `Total Quantity` / sum(`Total Quantity`))

df15N <- plasticN  %>%
  filter(year == 2015) %>% 
  group_by(year, month) %>%
  mutate(freq = `Total Quantity` / sum(`Total Quantity`))

df16N <- plasticN  %>%
  filter(year == 2016) %>% 
  group_by(year, month) %>%
  mutate(freq = `Total Quantity` / sum(`Total Quantity`))

df17N <- plasticN  %>%
  filter(year == 2017) %>% 
  group_by(year, month) %>%
  mutate(freq = `Total Quantity` / sum(`Total Quantity`))

df18N <- plasticN  %>%
  filter(year == 2018) %>% 
  group_by(year, month) %>%
  mutate(freq = `Total Quantity` / sum(`Total Quantity`)) 

df19N <- plasticN  %>%
  filter(year == 2019) %>% 
  group_by(year, month) %>%
  mutate(freq = `Total Quantity` / sum(`Total Quantity`)) 

dfTotN <- rbind(df12N, df13N, df14N, df15N, df16N, df17N, df18N, df19N)
@

\begin{figure}[H] 
\begin{center}
<<>>=
# plot for observing the data
(time_plotfr2N <- ggplot(dfTotN, aes(x = year, y = freq, color=category, fill = category)) +
  geom_smooth(method="lm", level=0.95) +
  theme_bw() + 
  xlab("Years") +
  ylab("relative frequency") +
  expand_limits(y=0) +
  scale_y_continuous() + 
  scale_x_continuous()+
  theme(legend.position="bottom")+
  theme(legend.text = element_text(size=5, face="bold")))
@
\caption {Portion of plastic}
\label{figG1}
\end {center}
\end {figure}


In this graphical representation of the relative frequency of the 5 different categories of plastic debris over the years, the insight to derive is that "Cigarette related waste, "Food related waste" and "Fragments" seem to experience some change, whereas "Other" and "Plastic bags and styrofoam packaging" seem to remain steady. A model is then created and tested on untrained data to see the early indications still stand.

<<>>=
# create train and test set
n <- nrow(dfTotN)  # Number of observations
ntrain <- round(n*0.75)  # 75% for training set
set.seed(314)    # Set seed for reproducible results
tindex <- sample(n, ntrain)   # Create a random index
train_dfTotN <- dfTotN[tindex,]   # Create training set
test_dfTotN <- dfTotN[-tindex,]
@

<<>>=
# modelling for category "Cigarette related waste"

train_Cigrel <- train_dfTotN %>% 
  filter(category=="Cigarette related waste") %>% 
  group_by(year)

test_Cigrel <- test_dfTotN %>% 
  filter(category=="Cigarette related waste") %>% 
  group_by(year)

set.seed(1234)
train_Cigrel.modelN <- lm(freq ~ year, data = train_Cigrel)
summary(train_Cigrel.modelN)

print("PREDICTION")
pred_Cigrel <- predict(train_Cigrel.modelN, test_Cigrel)
summary(pred_Cigrel)

actuals_predsCigrel <- data.frame(cbind(actuals=test_Cigrel$freq, predicteds=pred_Cigrel)) 
head(actuals_predsCigrel)
correlation_accuracy <- cor(actuals_predsCigrel)
min_max_accuracy <- mean(apply(actuals_predsCigrel, 1, min) / apply(actuals_predsCigrel, 1, max))  
@


<<results='asis'>>=

print(xtable(correlation_accuracy),table.placement="H")

min_max_accuracy
@


<<>>=
# modelling for category "Food related waste"

train_Foodrel <- train_dfTotN %>% 
  filter(category=="Food related waste") %>% 
  group_by(year)

test_Foodrel <- test_dfTotN %>% 
  filter(category=="Food related waste") %>% 
  group_by(year)

set.seed(1234)
train_Foodrel.modelN <- lm(freq ~ year, data = train_Foodrel)
summary(train_Foodrel.modelN)

print("PREDICTION")
pred_Foodrel <- predict(train_Foodrel.modelN, test_Foodrel)
summary(pred_Foodrel)

actuals_predsFoodrel <- data.frame(cbind(actuals=test_Foodrel$freq, predicteds=pred_Foodrel)) 
head(actuals_predsFoodrel)
correlation_accuracy <- cor(actuals_predsFoodrel)  
min_max_accuracy <- mean(apply(actuals_predsFoodrel, 1, min) / apply(actuals_predsFoodrel, 1, max))  
@


<<results='asis'>>=
print(xtable(correlation_accuracy),table.placement="H")
print(min_max_accuracy)
@


<<>>=
# modelling for category "Fragments"
train_Frag <- train_dfTotN %>% 
  filter(category=="Fragments") %>% 
  group_by(year)

test_Frag <- test_dfTotN %>% 
  filter(category=="Fragments") %>% 
  group_by(year)

set.seed(1234)
train_Frag.modelN <- lm(freq ~ year, data = train_Frag)
summary(train_Frag.modelN)

print("PREDICTION")
pred_Frag <- predict(train_Frag.modelN, test_Frag)
summary(pred_Frag)

actuals_predsFrag <- data.frame(cbind(actuals=test_Frag$freq, predicteds=pred_Frag)) 
head(actuals_predsFrag)
correlation_accuracy <- cor(actuals_predsFrag)  
min_max_accuracy <- mean(apply(actuals_predsFrag, 1, min) / apply(actuals_predsFrag, 1, max))  
@


<<results='asis'>>=
print(xtable(correlation_accuracy),table.placement="H")
print(min_max_accuracy)
@


<<>>=
# modelling for category "Other"
train_Other <- train_dfTotN %>% 
  filter(category=="Other") %>% 
  group_by(year)

test_Other <- test_dfTotN %>% 
  filter(category=="Other") %>% 
  group_by(year)

set.seed(1234)
train_Other.modelN <- lm(freq ~ year, data = train_Other)
summary(train_Other.modelN)

print("PREDICTION")
pred_Other <- predict(train_Other.modelN, test_Other)
summary(pred_Other)

actuals_predsOther <- data.frame(cbind(actuals=test_Other$freq, predicteds=pred_Other)) 
head(actuals_predsOther)
correlation_accuracy <- cor(actuals_predsOther)  # 5.31%
min_max_accuracy <- mean(apply(actuals_predsOther, 1, min) / apply(actuals_predsOther, 1, max))  
@


<<results='asis'>>=
print(xtable(correlation_accuracy),table.placement="H")
print(min_max_accuracy)
@


<<>>=
# modelling for category "Plastic bags and Styrofoam packaging"
train_Plbag <- train_dfTotN %>% 
  filter(category=="Plastic bags and Styrofoam packaging") %>% 
  group_by(year)

test_Plbag <- test_dfTotN %>% 
  filter(category=="Plastic bags and Styrofoam packaging") %>% 
  group_by(year)

set.seed(1234)
train_Plbag.modelN <- lm(freq ~ year, data = train_Plbag)
summary(train_Plbag.modelN)

print("PREDICTION")
pred_Plbag <- predict(train_Plbag.modelN, test_Plbag)
summary(pred_Plbag)

actuals_predsPlbag <- data.frame(cbind(actuals=test_Plbag$freq, predicteds=pred_Plbag)) 
head(actuals_predsPlbag)
correlation_accuracy <- cor(actuals_predsPlbag) 
min_max_accuracy <- mean(apply(actuals_predsPlbag, 1, min) / apply(actuals_predsPlbag, 1, max))  
@


<<results='asis'>>=
print(xtable(correlation_accuracy),table.placement="H")
print(min_max_accuracy)
@


<<>>=
plastic_category <-c("cigarette related waste", "food related waste","Fragments", 
                      "Other","Plastic bags and Styrofoam packaging" )

slope_scores <- c(-0.065,0.036, 0.030, -0.001, 0.001)
slope_interpretation <-c("downward", "upward", "upward", "steady", "steady")
p_value<-c("<0.05","<0.05","<0.05", ">0.05",">0.05")
adjRsquared <- c(0.51, 0.38, 0.16,  -0.004, -0.013)
corr_accuracy<-c(0.64, 0.62, 0.57, 0.14,-0.14)
min_max_Acc<-c(0.61,0.78,0.64, 0.73 ,0.69)

score_table1 <- data.frame(plastic_category, p_value,slope_scores, slope_interpretation, adjRsquared)
score_table2 <- data.frame(plastic_category, corr_accuracy, min_max_Acc)
@


<<results='asis'>>=
xtable(score_table1)

xtable(score_table2)
@


\subsection{Model Evaluation}

On metrics presented on table:\\

$Pr(>|t|)$ is the p-value, defined as the probability of observing any value equal or larger than t if H0 is true. The larger the t statistic, the smaller the p-value. Generally, a 0.05 cutoff is used for significance. When p-values are smaller than 0.05, the hypothesis is rejected given that there is no significant difference between the means. If the p-value is larger than 0.05, it cannot conclude that a significant difference exists.\\

Correlation accuracy:\\
A simple correlation between the actuals and predicted values can be used as a form of accuracy measure.\\
A higher correlation accuracy implies that the actuals and predicted values have similar directional movement, that is, when the actuals values increase the predicted values also increase and vice-versa.\\

MinMax Accuracy:\\
MinMax indicates how far off the model's prediction is. For a perfect model, this measure is 1.0. The lower the measure, the worse the performance of the model based on out-of-sample performance.

Adjusted R squared:\\
R-Squared gives the proportion of variation in the dependent (response) variable that has been explained by this model. Adjusted R-Squared is formulated such that it penalises the number of terms of the model.\\


On scores of metrics:\\

MinMax Accuracy is generally above 60\%, but never exceeds 78\% for all cases, which means that the model does a moderate job in predicting accurately the relative frequency of each category over time. The correlation accuracy is really good for "cigarette related waste" category, but not that good for "food related waste" and "Fragments" categories, which implies that the predicted values do not always follow the true values observed in the same proportion. The categories "Other" and "Plastic bags and Styrofoam packaging", where p-value is worse, score extremely low and negative values, respectively, which is troublesome. The higher the adjusted R squared metric the better. What is alarming here regarding this metric measure is the model created to predict for the last two categories, since it receives negative values.\\

In total we see that time is statistically significant in the change of proportions of certain categories
of plastic waste: "cigarette related waste", "food related waste", "fragments", causing a downward, upward and upward movement respectively. This is not the case for the "Other" and "Plastic bags and Styrofoam packaging" categories, where though the models predicts a stagnation, there does not seem to be enough statistical evidence backing the credibility of the predictions of these two models.\\


In total we see that time is statistically significant in the change of proportions of certain categories of plastic waste: "cigarette related waste", "food related waste", "fragments", causing a downward, upward and upward movement respectively. This is not the case for the "Other" and "Plastic bags and Styrofoam packaging" categories, where though the models predicts a stagnation, there does not seem to be enough statistical evidence backing the credibility of the predictions of these two models.\\

It is important to notice that since it is a linear regression model, there exist no hyper-parameters for tuning, therefore no cross-validation comes in play. Since, only one predictor is used any kind of stepwise elimination is redundant. So, evaluation relies on metrics used.\\




\subsection{Model Discussion}


As seen in the study of debris in a Eastern Mediterranean coastal town \cite{PORTMAN2017} the variability of non-plastic litter composition should make us aware that the local context must be taken into account. Perhaps, given that non-plastic litter is a hugely varying category, this way of thinking could be expanded into the plastic debris category of "Other", given that it is inherently varied let alone in a dataset that gathers information over the entire world. In fact, this could in reverse explain the higher p-value, since high variation within the category studied would yield results of insufficient trustworthiness. 

As mentioned in \cite{BROWNE2015} many intertidal sites seem to be transit areas for debris, with exports matching imports over time. This could hugely impact a created model especially given that in the dataset we used we didn't have such information available. It is also important to acknowledge that our dataset is North American centred which and given that it has information gathered over a period of 10 years we cannot be sure of categorisation bias in the data, since there is no proof of a single sampling protocol followed. 



\pagebreak
\section{Conclusion and Future Work}

As indicated by Jambeck et al.\cite{JAMBECK2015} 4-12 million tons of plastic waste generated worldwide will enter the marine ecosystem every year. Our results shows that there is little change in the percentage of marine debris that were recorded as plastic over time. However the recorded data are not in the same frequency every year and depend on beach clean ups and other initiatives. Since these events aim mostly to clean-ups after big social events, extra effort might have been made to retrieve entertainment based debris such as fireworks, food packaging and six pack rings. \\

The results in this report confirm the fact that plastic is the most abundant litter in the marine environment globally. Plastic was included in the 68\% of the observations recorded and it made up of over 70\% of the quantity of debris that was recorded. The results also indicate it is possible to successfully use citizen science projects to monitor marine pollution. There are various ways citizen science projects have been used for and here we focused on distribution and composition of marine litter on a global scale. Identifying the amount and type of debris can help in identifying the sources of pollution. This can then aid to find out ways to reduce the source in the first place. Event driven pollution such as fireworks also plays a role in marine pollution and this can be reduced by raising awareness amongst the public and trying to find more sustainable ways of celebrating events. The fact that plastic composition does not change over time is also quite alarming. Although there have been a lot of awareness programmes in the last decades, more needs to be done to see these changes that can reduce the damage done by plastic pollution.  \\

Future work can include looking at the marine pollution debris in smaller scale by regions. Each region is different and there are various factors that can affect the data observations such as the frequency of data submissions are not at the same time everywhere.  Since MDT is more focused on North America, this opportunity might be used to educate about it in other regions of the world. Although we will never be able to identify the real sources of pollution, it can help in raising awareness of the damage done by plastic pollution in the marine environment and make the public more environmentally conscious. Regulations to discourage single use plastic items and smoking in public places have been enforced in many countries. It would be interesting to look at the effect these are having on the marine debris pollution worldwide. However, more time and data will be required to see the change at a global scale. \\

Another line of study might be for example to compare the decreasing rate of cigarette use with the decreasing observation of cigarette debris which had been observed over the years to see if there is a correlation there which was hypothesised but never investigated due to not being within the direct inquiry of the report. It would also be useful to invest time and resources into a non-citizen science alternative to data collection, in order to avoid the large spikes in observations during specifictimes such as world clean-ups day in order to get a more rounded dataset.   \\  

Lots of beach clean ups and litter collections are done in the beaches worldwide to estimate the marine pollution. However, the majority (70\%) of the marine debris are not on the surface but on the seafloor. More research and studies are needed to accurately estimate the pollution in our oceans. Although marine pollution is a global issue, more needs to be done locally to reduce the sources of the pollution. In addition, standardised monitoring protocol and global partnerships are essential for efficient management of marine plastic pollution. \\


\pagebreak
\section{Project Management}\label{mgt}
\subsection{Tools and Technologies}

Group 2 communicated primarily using a dedicated Slack channel, with project materials managed on a Github repository, and weekly 1 hour in-person meetings. Slack was useful for making announcements; threaded conversations for topics if someone had a question; polling features which were used to collect votes, for example on deciding the topic of the research; but perhaps most importantly the integration with Github meant the group was automatically notified every time there was an update available for project materials, keeping members up to date at all times. Git controls on github meant document integrity was also maintained and there were no issues with persons working on materials which had become outdated and needed manual extraction and merging.\\

All project material used and the final report can be accessed from the \textit{\href{https://github.com/KarenJewell/CMM507Group2}{Public Github Repository}} \\

In March 2020, the outbreak of the global Covid-19 pandemic and resulting lockdown measures enforced by the UK government, came into effect midway through this project. Fortunately, because online collaboration tools were already established and actively used, the "Stay at Home" order had little impact on the group's ability to complete work while remaining safely at home. Slack continued to be the main commmunication medium, with weekly 1 hour Skype calls replacing the original in-person meetings.\\


\subsection{Project Progress}

The group operated on a cyclical "divide and conquer" approch. In the weekly meetings, the scope for the week was agreed then divided into parts for group members to volunteer and adopt, working on it in the week. At the next meeting, the work was consolidated with individuals briefly presenting what they had achieved in the week, or what they may have found difficulty progressing. The newly converged scope was then again divided for the next week, so the cycle repeats ensuring each individual had a clear task for the week ahead and the whole group retained an awareness of what other work was being done and who was doing it. The discussions of each weekly meeting were also documented and hosted on the shared Github for all members to reference. This approach ensured there was continous progress throughout the project timeline while also allowing individuals the flexibility to manage their time around all other personal and professional commitments. \\

<<echo=FALSE,results='asis'>>=
require(openxlsx);
require(readxl)
library(stringr);library(data.table)
library(XLConnect)
library(xtable)

# Sheets names 
fileName <- 'data/meetings.xlsx'
sheets <- readxl::excel_sheets(fileName)
#length(sheets)
# read sheet into dataframe, and rbind
dfs <- readWorksheet(loadWorkbook("data/meetings.xlsx"),sheet=1)
dfs$Date <-as.character(dfs$Date)
print(xtable(dfs,
                    caption = "Record of Team Meetings", 
                    label = "tab:one", 
                    # align changes subject to number of columns 
                    align = "lllp{7cm}lllll"),include.rownames=FALSE,
                    caption.placement = "top",
                    floating=TRUE,
                    type="latex",
                    table.placement = "H")
@




\subsection{Peer Assessment}

The Peer Assessment Table presents the peer and self assement scores for all five of Group 2's members.\\

<<echo=FALSE,results='asis'>>=
require(openxlsx);
require(readxl)
library(stringr);library(data.table)
library(XLConnect)
library(xtable)

# Sheets names 
fileName <- 'data/peers.xlsx'
sheets <- readxl::excel_sheets(fileName)
#length(sheets)
# read sheet into dataframe, and rbind
dfs <- readWorksheet(loadWorkbook("data/peers.xlsx"),sheet=1)

# convert fields into chars
dfs[, ] <- lapply(dfs[, ], as.character)

print(xtable(dfs,
                    caption = "Peer Assessment out of 100", 
                    label = "tab:two", 
                    # align changes subject to number of columns 
                    align = "lllllll"),include.rownames=FALSE,
                    caption.placement = "top",
                    floating=TRUE,
                    type="latex",
                    table.placement = "H" )

    
@


The tasks of the project were shared justly across the members of the group. Alex Aided in the research of appropriate papers for the project and writing sections for the final report. Georgios sourced for datasets, reviewed literature, wrote for the final report and lead in creating and assessing the linear regression model.Karen acted as a facillitator and document controller for the project, responsible for editing the final report and ensuring it compiled successfully. Roshi acted as lead for finding relevant literatures for the study, writing sections and editing the final report. Stuart sourced the dataset and lead in the exploratory data analysis, producing visualisations for the final report.\\


\pagebreak
\section*{References}\label{pubs}
\printbibliography[heading=none]

\end{document}
