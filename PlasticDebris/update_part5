---
title: "models over categories 9 5 2020"
author: "go"
date: "9/5/2020"
output: pdf_document
---

# copy and paste the code below under the following part:
```{r}
topLocations <- data %>% 
  group_by(Location) %>% 
  summarise(sumQuantity = sum(Quantity)) %>% 
  arrange(desc(sumQuantity)) %>% 
  top_n(5,sumQuantity)

data %>% 
  filter(Location %in% topLocations$Location) %>% 
  group_by(Location, `Material Description`) %>% 
  summarise(sumQuantity = sum(Quantity)) %>% 
  arrange(desc(sumQuantity)) %>% 
  ggplot(aes(x = `Material Description`, y = sumQuantity, fill = Location)) +
    geom_col()
```
###

```{r GetPlastic&Categorise}
recategorise <- function(x){
  out = ""
  if(x %in% c(1,4,6,22)){out = "Cigarette related waste"}
  if(x %in% c(2,3,7,9,10,17,23,11)) out = "Food related waste"
  if(x %in% c(8,14,15,16,18,19,21,20)) out = "Other"
  if(x %in% c(12,13)) out = "Plastic bags and Styrofoam packaging"
  if(x %in% c(5,23,24,25)) out = "Fragments"
  if(out == "") stop(paste("Error in recategorise:", x))
  return(out)
}
plastic_types <- data %>% 
  filter(`Material Description` == "PLASTIC") %>% 
  select(ItemName, ItemID) %>% 
  distinct() %>% 
  mutate(label = 1:n()) %>% 
  mutate(Category = purrr::map(label, recategorise)) %>%
  mutate(Category = as_factor(as.character(Category))) %>% 
  select(ItemID, Category)
plastic <- data %>% 
  filter(`Material Description` == "PLASTIC") %>% 
  full_join(plastic_types, by = "ItemID")



```

New code: 
```{r}
#9/5/20
library(MASS) 
plasticN <- plastic %>% 
  mutate(month = month(Time, label = FALSE), year = as.integer(year(Time))) %>% 
  filter(year > 2010) %>% 
  group_by(year, category, month) %>%
  summarise(`Total Quantity` = sum(Quantity))




```





```{r}
#9/5/20
 
plasticN <- plastic %>% 
  mutate(month = month(Time, label = FALSE), year = as.integer(year(Time))) %>% 
  filter(year > 2010) %>% 
  group_by(year, category, month) %>%
  summarise(`Total Quantity` = sum(Quantity))
```

```{r}
#9/5/20
####

library(dplyr)
df11N <- plasticN  %>%
  filter(year == 2011) %>% 
  group_by(year, month) %>%
  mutate(freq = `Total Quantity` / sum(`Total Quantity`))

df12N <- plasticN  %>%
  filter(year == 2012) %>% 
  group_by(year, month) %>%
  mutate(freq = `Total Quantity` / sum(`Total Quantity`))


df13N <- plasticN  %>%
  filter(year == 2013) %>% 
  group_by(year, month) %>%
  mutate(freq = `Total Quantity` / sum(`Total Quantity`))


df14N <- plasticN  %>%
  filter(year == 2014) %>% 
  group_by(year, month) %>%
  mutate(freq = `Total Quantity` / sum(`Total Quantity`))

df15N <- plasticN  %>%
  filter(year == 2015) %>% 
  group_by(year, month) %>%
  mutate(freq = `Total Quantity` / sum(`Total Quantity`))


df16N <- plasticN  %>%
  filter(year == 2016) %>% 
  group_by(year, month) %>%
  mutate(freq = `Total Quantity` / sum(`Total Quantity`))



df17N <- plasticN  %>%
  filter(year == 2017) %>% 
  group_by(year, month) %>%
  mutate(freq = `Total Quantity` / sum(`Total Quantity`))


df18N <- plasticN  %>%
  filter(year == 2018) %>% 
  group_by(year, month) %>%
  mutate(freq = `Total Quantity` / sum(`Total Quantity`)) 

df19N <- plasticN  %>%
  filter(year == 2019) %>% 
  group_by(year, month) %>%
  mutate(freq = `Total Quantity` / sum(`Total Quantity`)) 


dfTotN <- rbind(df11N, df12N, df13N, df14N, df15N, df16N, df17N, df18N, df19N)

# plot for observing the data
(time_plotfr2N <- ggplot(dfTotN, aes(x = year, y = freq, color=category, fill = category)) +
  geom_smooth(method="lm", level=0.95) +
  theme_bw() + 
  xlab("Years") +
  ylab("relative frequency") +
  ggtitle("portion of plastic") + 
  expand_limits(y=0) +
  scale_y_continuous() + 
  scale_x_continuous()+
  theme(legend.position="bottom")+
  theme(legend.text = element_text(size=5, face="bold")))


```


We see here a graphical representation of the relative frequency of the 5 different categories of plastic debris over the years. The hint we are getting here is that "Cigarette realted waste, "Food related waste", "Fragments" seem to experiance some change, whereas "Other" and Plastic bags and styrofoam packaging" seem to remain steady. We go on and create a model and test it on untrained data to see if what is the actual case.


```{r}
#9/5/20
### MODELING with new categorisation


# create train and test set
n <- nrow(dfTotN)  # Number of observations
ntrain <- round(n*0.75)  # 75% for training set
set.seed(314)    # Set seed for reproducible results
tindex <- sample(n, ntrain)   # Create a random index
train_dfTotN <- dfTotN[tindex,]   # Create training set
test_dfTotN <- dfTotN[-tindex,]

# modelling for category "Cigarette related waste"

train_Cigrel <- train_dfTotN %>% 
  filter(category=="Cigarette related waste") %>% 
  group_by(year)

test_Cigrel <- test_dfTotN %>% 
  filter(category=="Cigarette related waste") %>% 
  group_by(year)

set.seed(1234)
train_Cigrel.modelN <- lm(freq ~ year, data = train_Cigrel)
summary(train_Cigrel.modelN)

print("PREDICTION")
pred_Cigrel <- predict(train_Cigrel.modelN, test_Cigrel)
summary(pred_Cigrel)

actuals_predsCigrel <- data.frame(cbind(actuals=test_Cigrel$freq, predicteds=pred_Cigrel)) 
head(actuals_predsCigrel)
correlation_accuracy <- cor(actuals_predsCigrel)
min_max_accuracy <- mean(apply(actuals_predsCigrel, 1, min) / apply(actuals_predsCigrel, 1, max))  

mape <- mean(abs((actuals_predsCigrel$predicteds - actuals_predsCigrel$actuals))/actuals_predsCigrel$actuals)

correlation_accuracy

min_max_accuracy

mape
```


```{r}
#9/5/20
# modelling for category "Food related waste"
train_Foodrel <- train_dfTotN %>% 
  filter(category=="Food related waste") %>% 
  group_by(year)

test_Foodrel <- test_dfTotN %>% 
  filter(category=="Food related waste") %>% 
  group_by(year)

set.seed(1234)
train_Foodrel.modelN <- lm(freq ~ year, data = train_Foodrel)
summary(train_Foodrel.modelN)

print("PREDICTION")
pred_Foodrel <- predict(train_Foodrel.modelN, test_Foodrel)
summary(pred_Foodrel)

actuals_predsFoodrel <- data.frame(cbind(actuals=test_Foodrel$freq, predicteds=pred_Foodrel)) 
head(actuals_predsFoodrel)
correlation_accuracy <- cor(actuals_predsFoodrel)  
min_max_accuracy <- mean(apply(actuals_predsFoodrel, 1, min) / apply(actuals_predsFoodrel, 1, max))  
# => 53.73%, min_max accuracy
mape <- mean(abs((actuals_predsFoodrel$predicteds - actuals_predsFoodrel$actuals))/actuals_predsFoodrel$actuals)

correlation_accuracy
min_max_accuracy
mape
```


```{r}

#9/5/20
# modelling for category "Other"
train_Other <- train_dfTotN %>% 
  filter(category=="Other") %>% 
  group_by(year)

test_Other <- test_dfTotN %>% 
  filter(category=="Other") %>% 
  group_by(year)

set.seed(1234)
train_Other.modelN <- lm(freq ~ year, data = train_Other)
summary(train_Other.modelN)

print("PREDICTION")
pred_Other <- predict(train_Other.modelN, test_Other)
summary(pred_Other)

actuals_predsOther <- data.frame(cbind(actuals=test_Other$freq, predicteds=pred_Other)) 
head(actuals_predsOther)
correlation_accuracy <- cor(actuals_predsOther)  # 5.31%
min_max_accuracy <- mean(apply(actuals_predsOther, 1, min) / apply(actuals_predsOther, 1, max))  
mape <- mean(abs((actuals_predsOther$predicteds - actuals_predsOther$actuals))/actuals_predsOther$actuals)

correlation_accuracy
min_max_accuracy
mape
```


```{r}
#9/5/20
# modelling for category "Plastic bags and Styrofoam packaging"
train_Plbag <- train_dfTotN %>% 
  filter(category=="Plastic bags and Styrofoam packaging") %>% 
  group_by(year)

test_Plbag <- test_dfTotN %>% 
  filter(category=="Plastic bags and Styrofoam packaging") %>% 
  group_by(year)

set.seed(1234)
train_Plbag.modelN <- lm(freq ~ year, data = train_Plbag)
summary(train_Plbag.modelN)

print("PREDICTION")
pred_Plbag <- predict(train_Plbag.modelN, test_Plbag)
summary(pred_Plbag)

actuals_predsPlbag <- data.frame(cbind(actuals=test_Plbag$freq, predicteds=pred_Plbag)) 
head(actuals_predsPlbag)
correlation_accuracy <- cor(actuals_predsPlbag)  # 5.31%
min_max_accuracy <- mean(apply(actuals_predsPlbag, 1, min) / apply(actuals_predsPlbag, 1, max))  
mape <- mean(abs((actuals_predsPlbag$predicteds - actuals_predsPlbag$actuals))/actuals_predsPlbag$actuals)

correlation_accuracy
min_max_accuracy
mape
```


```{r}
#9/5/20
# modelling for category "Fragments"
train_Frag <- train_dfTotN %>% 
  filter(category=="Fragments") %>% 
  group_by(year)

test_Frag <- test_dfTotN %>% 
  filter(category=="Fragments") %>% 
  group_by(year)

set.seed(1234)
train_Frag.modelN <- lm(freq ~ year, data = train_Frag)
summary(train_Frag.modelN)

print("PREDICTION")
pred_Frag <- predict(train_Frag.modelN, test_Frag)
summary(pred_Frag)

actuals_predsFrag <- data.frame(cbind(actuals=test_Frag$freq, predicteds=pred_Frag)) 
head(actuals_predsFrag)
correlation_accuracy <- cor(actuals_predsFrag)  # 5.31%
min_max_accuracy <- mean(apply(actuals_predsFrag, 1, min) / apply(actuals_predsFrag, 1, max))  
mape <- mean(abs((actuals_predsFrag$predicteds - actuals_predsFrag$actuals))/actuals_predsFrag$actuals)

correlation_accuracy
min_max_accuracy
mape
```

#9/5/20
In total we see that time is statistically significant in the change of proportions of certain categories
of plastic waste: "cigarette related waste", "food related waste", "fragments". This is not the case for the "Other" and "Plastic bags and Styrofoam packaging" .
Some plastic waste categories are time variant while others aren't and this has to do a  lot with sampling techniques and one-sidedness of datasets. It does not mean that the datasets are wrong it just shows even more that what we have talked about over many group meetings regarding the dataset being biased one way or the other is clearly backed by statistical evidence within this dataset and by referencial evidence too."

"Paper: Spatial and Temporal Patterns of Stranded Intertidal Marine Debris:
Is There a Picture of Global Change?"


```{r}
plastic_category <-(c("cigarette related waste", "food related waste","Fragments", "Other","Plastic bags and Styrofoam packaging" ))
slope_scores <- c(-0.05512,0.030425, 0.030950,-0.002428,-0.001151)
slope_interpretation <-c("downward", "upward", "upward", "relatively steady", "relatively steady")
p_value<-c("<0.05","<0.05","<0.05", ">0.05",">0.05")
corr_accuracy<-c(0.62, 0.35,0.48, 0.27,0.38)
min_max_Acc<-c(0.67,0.72,0.67, 0.65 ,0.67)
MAPE_scores<-c(0.99,0.91,0.54, 0.89, 0.43)
score_table <- data.frame(plastic_category, p_value,slope_scores, slope_interpretation, corr_accuracy,min_max_Acc, MAPE_scores)
score_table
```

On metrics used:
Pr(>|t|) is the p-value, defined as the probability of observing any value equal or larger than t if H0 is true. The larger the t statistic, the smaller the p-value. Generally, we use 0.05 as the cutoff for significance. When p-values are smaller than 0.05, we reject H0 that there's no difference between the means and conclude that a significant difference does exist. If the p-value is larger than 0.05, we cannot conclude that a significant difference exists. P-value<0.05 means that there is statistical significance in the results presented. If p-value>0.05 we can not conclude on the statistical significance. 

Correlation accuracy:
A simple correlation between the actuals and predicted values can be used as a form of accuracy measure.
A higher correlation accuracy implies that the actuals and predicted values have similar directional movement, i.e. when the actuals values increase the predicted values also increase and vice-versa.

MinMax Accuracy:
MinMax tells you how far the model's prediction is off. For a perfect model, this measure is 1.0. The lower the measure, the worse the model, based on out-of-sample performance.
min_max_accuracy

MAPE:
The mean absolute percentage error (MAPE) is a statistical measure of how accurate a forecast system is. It measures this accuracy as a percentage, and can be calculated as the average absolute percent error for each time period minus actual values divided by actual values. 
eg a MAPE value of 0.99 states that our model’s predictions are, on average, 0.99% off from actual value.

On values of metrics used:
MinMax Accuracy is generally above 65% but never exceeds 72% for all cases, which means that the model does a moderate job in predicting accurately the relative frequency of each category over time.
The correlation accuracy is not that good which implies that the predicted values do not always follow the true values observed. The best value is for the model predicting on "cigarette related waste".
MAPE scores are pretty good for all models showing that no model's predictions are on average more than 1% off from actual value. 
