---
title: "frfr"
author: "go"
date: "10/5/2020"
output: html_document
---


```{r}

plasticN <- plastic %>% 
  mutate(month = month(Time, label = FALSE), year = as.integer(year(Time))) %>% 
  filter(year > 2010) %>% 
  group_by(year, category, month) %>%
  summarise(`Total Quantity` = sum(Quantity))
```


```{r}

library(dplyr)

df12N <- plasticN  %>%
  filter(year == 2012) %>% 
  group_by(year, month) %>%
  mutate(freq = `Total Quantity` / sum(`Total Quantity`))


df13N <- plasticN  %>%
  filter(year == 2013) %>% 
  group_by(year, month) %>%
  mutate(freq = `Total Quantity` / sum(`Total Quantity`))


df14N <- plasticN  %>%
  filter(year == 2014) %>% 
  group_by(year, month) %>%
  mutate(freq = `Total Quantity` / sum(`Total Quantity`))

df15N <- plasticN  %>%
  filter(year == 2015) %>% 
  group_by(year, month) %>%
  mutate(freq = `Total Quantity` / sum(`Total Quantity`))


df16N <- plasticN  %>%
  filter(year == 2016) %>% 
  group_by(year, month) %>%
  mutate(freq = `Total Quantity` / sum(`Total Quantity`))



df17N <- plasticN  %>%
  filter(year == 2017) %>% 
  group_by(year, month) %>%
  mutate(freq = `Total Quantity` / sum(`Total Quantity`))


df18N <- plasticN  %>%
  filter(year == 2018) %>% 
  group_by(year, month) %>%
  mutate(freq = `Total Quantity` / sum(`Total Quantity`)) 

df19N <- plasticN  %>%
  filter(year == 2019) %>% 
  group_by(year, month) %>%
  mutate(freq = `Total Quantity` / sum(`Total Quantity`)) 


dfTotN <- rbind(df12N, df13N, df14N, df15N, df16N, df17N, df18N, df19N)

# plot for observed the data
(time_plotfr2N <- ggplot(dfTotN, aes(x = year, y = freq, color=category, fill = category)) +
  geom_smooth(method="lm", level=0.95) +
  theme_bw() + 
  xlab("Years") +
  ylab("relative frequency") +
  ggtitle("portion of plastic") + 
  expand_limits(y=0) +
  scale_y_continuous() + 
  scale_x_continuous()+
  theme(legend.position="bottom")+
  theme(legend.text = element_text(size=5, face="bold")))


```

We see here a graphical representation of the relative frequency of the 5 different categories of plastic debris over the years. The hint we are getting here is that "Cigarette realted waste, "Food related waste", "Fragments" seem to experiance some change, whereas "Other" and "Plastic bags and styrofoam packaging" seem to remain steady. We go on and create a model and test it on untrained data to see what is the actual case.

```{r}
# create train and test set
n <- nrow(dfTotN)  # Number of observations
ntrain <- round(n*0.75)  # 75% for training set
set.seed(314)    # Set seed for reproducible results
tindex <- sample(n, ntrain)   # Create a random index
train_dfTotN <- dfTotN[tindex,]   # Create training set
test_dfTotN <- dfTotN[-tindex,]

# modelling for category "Cigarette related waste"

train_Cigrel <- train_dfTotN %>% 
  filter(category=="Cigarette related waste") %>% 
  group_by(year)

test_Cigrel <- test_dfTotN %>% 
  filter(category=="Cigarette related waste") %>% 
  group_by(year)

set.seed(1234)
train_Cigrel.modelN <- lm(freq ~ year, data = train_Cigrel)
summary(train_Cigrel.modelN)

print("PREDICTION")
pred_Cigrel <- predict(train_Cigrel.modelN, test_Cigrel)
summary(pred_Cigrel)

actuals_predsCigrel <- data.frame(cbind(actuals=test_Cigrel$freq, predicteds=pred_Cigrel)) 
head(actuals_predsCigrel)
correlation_accuracy <- cor(actuals_predsCigrel)
min_max_accuracy <- mean(apply(actuals_predsCigrel, 1, min) / apply(actuals_predsCigrel, 1, max))  


correlation_accuracy

min_max_accuracy
```


```{r}
# modelling for category "Food related waste"
train_Foodrel <- train_dfTotN %>% 
  filter(category=="Food related waste") %>% 
  group_by(year)

test_Foodrel <- test_dfTotN %>% 
  filter(category=="Food related waste") %>% 
  group_by(year)

set.seed(1234)
train_Foodrel.modelN <- lm(freq ~ year, data = train_Foodrel)
summary(train_Foodrel.modelN)

print("PREDICTION")
pred_Foodrel <- predict(train_Foodrel.modelN, test_Foodrel)
summary(pred_Foodrel)

actuals_predsFoodrel <- data.frame(cbind(actuals=test_Foodrel$freq, predicteds=pred_Foodrel)) 
head(actuals_predsFoodrel)
correlation_accuracy <- cor(actuals_predsFoodrel)  
min_max_accuracy <- mean(apply(actuals_predsFoodrel, 1, min) / apply(actuals_predsFoodrel, 1, max))  

correlation_accuracy
min_max_accuracy
```


```{r}
# modelling for category "Fragments"
train_Frag <- train_dfTotN %>% 
  filter(category=="Fragments") %>% 
  group_by(year)

test_Frag <- test_dfTotN %>% 
  filter(category=="Fragments") %>% 
  group_by(year)

set.seed(1234)
train_Frag.modelN <- lm(freq ~ year, data = train_Frag)
summary(train_Frag.modelN)

print("PREDICTION")
pred_Frag <- predict(train_Frag.modelN, test_Frag)
summary(pred_Frag)

actuals_predsFrag <- data.frame(cbind(actuals=test_Frag$freq, predicteds=pred_Frag)) 
head(actuals_predsFrag)
correlation_accuracy <- cor(actuals_predsFrag)  
min_max_accuracy <- mean(apply(actuals_predsFrag, 1, min) / apply(actuals_predsFrag, 1, max))  

correlation_accuracy
min_max_accuracy
```


```{r}
# modelling for category "Other"
train_Other <- train_dfTotN %>% 
  filter(category=="Other") %>% 
  group_by(year)

test_Other <- test_dfTotN %>% 
  filter(category=="Other") %>% 
  group_by(year)

set.seed(1234)
train_Other.modelN <- lm(freq ~ year, data = train_Other)
summary(train_Other.modelN)

print("PREDICTION")
pred_Other <- predict(train_Other.modelN, test_Other)
summary(pred_Other)

actuals_predsOther <- data.frame(cbind(actuals=test_Other$freq, predicteds=pred_Other)) 
head(actuals_predsOther)
correlation_accuracy <- cor(actuals_predsOther)  # 5.31%
min_max_accuracy <- mean(apply(actuals_predsOther, 1, min) / apply(actuals_predsOther, 1, max))  

correlation_accuracy
min_max_accuracy
```


```{r}
# modelling for category "Plastic bags and Styrofoam packaging"
train_Plbag <- train_dfTotN %>% 
  filter(category=="Plastic bags and Styrofoam packaging") %>% 
  group_by(year)

test_Plbag <- test_dfTotN %>% 
  filter(category=="Plastic bags and Styrofoam packaging") %>% 
  group_by(year)

set.seed(1234)
train_Plbag.modelN <- lm(freq ~ year, data = train_Plbag)
summary(train_Plbag.modelN)

print("PREDICTION")
pred_Plbag <- predict(train_Plbag.modelN, test_Plbag)
summary(pred_Plbag)

actuals_predsPlbag <- data.frame(cbind(actuals=test_Plbag$freq, predicteds=pred_Plbag)) 
head(actuals_predsPlbag)
correlation_accuracy <- cor(actuals_predsPlbag) 
min_max_accuracy <- mean(apply(actuals_predsPlbag, 1, min) / apply(actuals_predsPlbag, 1, max))  

correlation_accuracy
min_max_accuracy
```


```{r}
plastic_category <-c("cigarette related waste", "food related waste","Fragments", 
                      "Other","Plastic bags and Styrofoam packaging" )

slope_scores <- c(-0.063,0.038, 0.034, 0.000, 0.001)
slope_interpretation <-c("downward", "upward", "upward", "steady", "steady")
p_value<-c("<0.05","<0.05","<0.05", ">0.05",">0.05")
adjRsquared <- c(0.4416, 0.4324, 0.2177,  -0.0146, -0.01195)
corr_accuracy<-c(0.83, 0.50, 0.41, -0.36,-0.12)
min_max_Acc<-c(0.78,0.77,0.69, 0.64 ,0.61)

score_table <- data.frame(plastic_category, p_value,slope_scores, 
                          slope_interpretation, adjRsquared, corr_accuracy,min_max_Acc)


score_table
```

On metrics presented on table:

Pr(>|t|) is the p-value, defined as the probability of observing any value equal or larger than t if H0 is true. The larger the t statistic, the smaller the p-value. Generally, we use 0.05 as the cutoff for significance. When p-values are smaller than 0.05, we reject H0 that there's no difference between the means and conclude that a significant difference does exist. If the p-value is larger than 0.05, we cannot conclude that a significant difference exists. P-value<0.05 means that there is statistical significance in the results presented. If p-value>0.05 we can not conclude on the statistical significance. 

Correlation accuracy:
A simple correlation between the actuals and predicted values can be used as a form of accuracy measure.
A higher correlation accuracy implies that the actuals and predicted values have similar directional movement, i.e. when the actuals values increase the predicted values also increase and vice-versa.

MinMax Accuracy:
MinMax tells you how far the model's prediction is off. For a perfect model, this measure is 1.0. The lower the measure, the worse the model, based on out-of-sample performance.
min_max_accuracy

Adjusted R squared:
R-Squared gives the proportion of variation in the dependent (response) variable that has been explained by this model. Adjusted R-Squared is formulated such that it penalises the number of terms of the model.


On scores of metrics:

MinMax Accuracy is generally above 60%, but never exceeds 78% for all cases, which means that the model does a moderate job in predicting accurately the relative frequency of each category over time. The correlation accuracy is really good for "cigarette related waste" category, but not that good for "food related waste" and "Fragments" categories, which implies that the predicted values do not always follow the true values observed in the same proportion. The categories "Other" and "Plastic bags and Styrofoam packaging", where p-value is worse, score negative values which is troublesome. The higher the adjusted R squared metric the better. What is alarming here regarding this metric measure is the model created to predict for the last two categories, since it receives negative values.

In total we see that time is statistically significant in the change of proportions of certain categories
of plastic waste: "cigarette related waste", "food related waste", "fragments", causing a downward, upward and upward movement respectively. This is not the case for the "Other" and "Plastic bags and Styrofoam packaging" categories, where though the models predicts a stagnation, there does not seem to be enough statistical evidence backing the credibility of the predictions of these two models.

It is important to notice that since it is a linear regression model, there exist no hyper-parameters for tuning, therefore no cross-validation comes in play. Since, only one predictor is used any kind of stepwise elimination is redundant. So, evaluation relies on metrics used.


